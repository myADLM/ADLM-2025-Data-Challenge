{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed6ceadb",
   "metadata": {},
   "source": [
    "# Analyzing the contextual annotations returned by Amazon Nova Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c92d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install matplotlib\n",
    "#%pip install polars\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e85663",
   "metadata": {},
   "source": [
    "## Cleaning up problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff02546",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_cache = Path(\"app/database/context/query_cache/amazon_nova_lite/\")\n",
    "\n",
    "bronze_df = pl.read_parquet(\"app/database/medallions/bronze.parquet\")\n",
    "silver_df = pl.read_parquet(\"app/database/medallions/silver.parquet\")\n",
    "df = bronze_df.join(silver_df, on=\"file_path\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c2c85",
   "metadata": {},
   "source": [
    "### Context tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53862d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "problems = 0\n",
    "pat = re.compile(r\"^<context>.*</context>$\", re.DOTALL)\n",
    "for blob in df[\"contextual_annotations\"]:\n",
    "    if re.match(pat, blob):\n",
    "        problems += 1\n",
    "\n",
    "print(problems)\n",
    "# 5729"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971a598c",
   "metadata": {},
   "source": [
    "### Context sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3fd4cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_context = df.filter(pl.col(\"contextual_annotations\").str.len_chars() == 0)\n",
    "len(empty_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba3ab06",
   "metadata": {},
   "source": [
    "1965 contexts have length=0, indicating that the model failed to generate any context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7372da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to generate context for 0 chunks across 0 files.\n"
     ]
    }
   ],
   "source": [
    "print(\"failed to generate context for %d chunks across %d files.\" % (len(empty_context.sort(by=[\"file_path\", \"chunk_index\"])), len(empty_context[\"file_path\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93bb18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file_path in empty_context[\"file_path\"].unique():\n",
    "    for record in empty_context.filter(pl.col(\"file_path\") == file_path).sort(pl.col(\"idx\"), descending=False).to_dicts():\n",
    "        output_path = Path(\"contexts\") / file_path[:-4] / f\"{record['chunk_index']}.txt\"\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        shutil.copy2(Path(\"app/database/originals\") / file_path, Path(\"contexts\") / file_path)\n",
    "        with open(output_path, \"w\") as f:\n",
    "            chunk = record[\"chunk_text\"]\n",
    "            f.write(f\"\"\"\n",
    "I have attached the whole document to this message.\n",
    "Here is the chunk we want to situate within the whole document\n",
    "<chunk>\n",
    "{chunk}\n",
    "</chunk>\n",
    "Please give a short succinct context to situate this chunk within the overall document for the purposes of improving search retrieval of the chunk. Answer only with the succinct context and nothing else.\n",
    "\"\"\")\n",
    "        finalized_file = Path(\"contexts\") / \"output\" / file_path[:-4] / f\"{record['chunk_index']}.txt\"\n",
    "        finalized_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(finalized_file, \"a\") as f:\n",
    "            f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "237bd18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in empty_context[\"file_path\"]:\n",
    "    for record in empty_context.filter(pl.col(\"file_path\") == file_path).sort(pl.col(\"idx\"), descending=False).to_dicts():\n",
    "        input_path = Path(\"contexts\") / \"output\" / file_path[:-4] / f\"{record['chunk_index']}.txt\"\n",
    "        output_path = Path(\"app/database/context/query_cache/amazon_nova_lite\") / file_path[:-4] / f\"{record['chunk_index']}.txt\"\n",
    "        if input_path.exists():\n",
    "            print(f\"writing {output_path}\")\n",
    "            shutil.copy2(input_path, output_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58afe666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (105_532,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>contextual_annotations</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Analytical Measurement section&quot;</td></tr><tr><td>&quot;Analytical Specificity Section&quot;</td></tr><tr><td>&quot;Reproducibility Results - EDTA&quot;</td></tr><tr><td>&quot;Precision data for ROMA scores&quot;</td></tr><tr><td>&quot;Analytical Sensitivity Studies&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;Interference by pH and specifi…</td></tr><tr><td>&quot;This chunk is from a 510(k) pr…</td></tr><tr><td>&quot;The analytical performance of …</td></tr><tr><td>&quot;The reproducibility study was …</td></tr><tr><td>&quot;This chunk comes from the stab…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (105_532,)\n",
       "Series: 'contextual_annotations' [str]\n",
       "[\n",
       "\t\"Analytical Measurement section\"\n",
       "\t\"Analytical Specificity Section\"\n",
       "\t\"Reproducibility Results - EDTA\"\n",
       "\t\"Precision data for ROMA scores\"\n",
       "\t\"Analytical Sensitivity Studies\"\n",
       "\t…\n",
       "\t\"Interference by pH and specifi…\n",
       "\t\"This chunk is from a 510(k) pr…\n",
       "\t\"The analytical performance of …\n",
       "\t\"The reproducibility study was …\n",
       "\t\"This chunk comes from the stab…\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort(pl.col(\"contextual_annotations\").str.len_chars(), descending=False)[\"contextual_annotations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39b0283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bunch of annotations contain only junk.\n",
    "silver_df = silver_df.with_columns(\n",
    "    pl.col(\"contextual_annotations\").map_elements(lambda x: \"\" if x == \"<snip>\" else x)\n",
    ")\n",
    "silver_df = silver_df.with_columns(\n",
    "    pl.col(\"contextual_annotations\").map_elements(lambda x: \"\" if x == \"context\" else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eb7a2589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (105_488,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>contextual_annotations</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Page 16&quot;</td></tr><tr><td>&quot;Page 14&quot;</td></tr><tr><td>&quot;table 17&quot;</td></tr><tr><td>&quot;Viewer B&quot;</td></tr><tr><td>&quot; 510(k) &quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;Interference from M+2 Isotopic…</td></tr><tr><td>&quot;Inclusivity To demonstrate the…</td></tr><tr><td>&quot;&lt;chunk&gt; \n",
       "&nbsp;&nbsp;&nbsp;&nbsp;510(k) SUBSTANTIA…</td></tr><tr><td>&quot;A clinical validation study wa…</td></tr><tr><td>&quot;&lt;chunk&gt;The VITEK 2 AST-GP Lefa…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (105_488,)\n",
       "Series: 'contextual_annotations' [str]\n",
       "[\n",
       "\t\"Page 16\"\n",
       "\t\"Page 14\"\n",
       "\t\"table 17\"\n",
       "\t\"Viewer B\"\n",
       "\t\" 510(k) \"\n",
       "\t…\n",
       "\t\"Interference from M+2 Isotopic…\n",
       "\t\"Inclusivity To demonstrate the…\n",
       "\t\"<chunk> \n",
       "    510(k) SUBSTANTIA…\n",
       "\t\"A clinical validation study wa…\n",
       "\t\"<chunk>The VITEK 2 AST-GP Lefa…\n",
       "]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    silver_df\n",
    "            .filter(pl.col(\"contextual_annotations\") != \"\")\n",
    "            .sort(pl.col(\"contextual_annotations\").str.len_chars(), descending=False)[\"contextual_annotations\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c7c1ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are still a bunch of crap annotations. I'm removing any annotation with length < 10\n",
    "silver_df = silver_df.with_columns(\n",
    "    pl.col(\"contextual_annotations\").map_elements(lambda x: \"\" if len(x) < 30 else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a740eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (104_178,)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>contextual_annotations</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Analytical Measurement section&quot;</td></tr><tr><td>&quot;Analytical Specificity Section&quot;</td></tr><tr><td>&quot;Reproducibility Results - EDTA&quot;</td></tr><tr><td>&quot;Precision data for ROMA scores&quot;</td></tr><tr><td>&quot;Analytical Sensitivity Studies&quot;</td></tr><tr><td>&hellip;</td></tr><tr><td>&quot;Interference from M+2 Isotopic…</td></tr><tr><td>&quot;Inclusivity To demonstrate the…</td></tr><tr><td>&quot;&lt;chunk&gt; \n",
       "&nbsp;&nbsp;&nbsp;&nbsp;510(k) SUBSTANTIA…</td></tr><tr><td>&quot;A clinical validation study wa…</td></tr><tr><td>&quot;&lt;chunk&gt;The VITEK 2 AST-GP Lefa…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (104_178,)\n",
       "Series: 'contextual_annotations' [str]\n",
       "[\n",
       "\t\"Analytical Measurement section\"\n",
       "\t\"Analytical Specificity Section\"\n",
       "\t\"Reproducibility Results - EDTA\"\n",
       "\t\"Precision data for ROMA scores\"\n",
       "\t\"Analytical Sensitivity Studies\"\n",
       "\t…\n",
       "\t\"Interference from M+2 Isotopic…\n",
       "\t\"Inclusivity To demonstrate the…\n",
       "\t\"<chunk> \n",
       "    510(k) SUBSTANTIA…\n",
       "\t\"A clinical validation study wa…\n",
       "\t\"<chunk>The VITEK 2 AST-GP Lefa…\n",
       "]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    silver_df\n",
    "            .filter(pl.col(\"contextual_annotations\") != \"\")\n",
    "            .sort(pl.col(\"contextual_annotations\").str.len_chars(), descending=False)[\"contextual_annotations\"] \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2b84c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we don't want any contextual annotations with length > 1/4 the length of the chunk\n",
    "silver_df = silver_df.with_columns(\n",
    "    pl.col(\"contextual_annotations\").map_elements(lambda x: \"\" if len(x) > 750 else x)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d07cd385",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_df.write_parquet(\"app/database/medallions/silver.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef697d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in silver_df.filter(pl.col(\"contextual_annotations\") == \"\").to_dicts():\n",
    "    with open(Path(\"app\") / \"database\" / \"context\" / \"query_cache\" / \"amazon_nova_lite\" / record[\"file_path\"][:-4] / f\"{record['chunk_index']}.txt\", \"w\") as f:\n",
    "        f.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931d175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(map(len, silver_df[\"contextual_annotations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0422b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "indigo-app-py3.11 (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
