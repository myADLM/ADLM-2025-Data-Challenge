# 510(k) SUBSTANTIAL EQUIVALENCE DETERMINATION DECISION SUMMARY

A. 510(k) Number: k130021   
B. Purpose for Submission: New device   
C. Manufacturer and Instrument Name: Philips Digital Pathology Philips Her2/neu IHC Digital Manual Read   
D. Type of Test or Tests Performed: Manual interpretation of digital images for immunohistochemically (IHC) stained HER2 slides

# E. System Descriptions:

1. Device Description:

The Philips Her2/neu IHC Digital Manual Read is a digital score application used with the Philips Digital Pathology Solution (DPS) platform that includes a Philips Ultra Fast Scanner (UFS) Philips Image Management System (IMS) and computer monitor. The Philips Digital Pathology Solution is an automated digital slide creation, management, sharing, viewing and analysis system. It is intended for in vitro diagnostic use as an aid to the pathologist in the display, detection, counting and classification of tissues and cells of clinical interest based on particular color, intensity, size, pattern and shape.

The Philips UFS digitizes glass slides at high resolution and generates images. First the Philips UFS takes snapshot images of the entire glass slide as well as the glass slide label and decodes the barcode. Based on the macro image of the slide, the scanner determines which region on the slide will be scanned. All images together with information about the decoded barcode are sent to the Philips Image Management System (Philips IMS).

The Phillips IMS runs on commercially available server and workstation IT hardware. The server stores and manages the digital slide images and digital slide metadata. The server supports interoperability with other information systems such as the laboratory information systems (LIS) via a HL7 interface. The IMS Web Viewer software provides the User Interface for the pathologist to view and read on the digital slides.

# 2. Principles of Operation:

The Philips Her2/neu IHC Digital Manual Read is intended to provide digital images to the pathologist to perform semi-quantitative interpretation of immunohistochemistry HER2/neu stained breast cancer specimens. Formalinfixed, paraffin embedded breast cancer specimens are stained with the Dako HercepTest™ according to the package insert. Slides are then scanned at a resolution of $0 . 2 5 { \mathrm { u m } }$ /pixel (equivalent to typical 40X objective) using the Philips UFS and stored digitally on the Philips IMS. The pathologist manually reads and interprets the digital image using the Philips IMS Web Viewer without use of image analysis software. The HER2 score is calculated by the pathologist based on the percentages of $0 , 1 + , 2 +$ , and $3 +$ cells according to the HER2 scoring scheme in the Dako HercepTest product insert.

3. Modes of Operation:

Automatic scanning with batch and random access modes

4. Specimen Identification:

Specimens are identified by slide label. The slide label includes a barcode and a readable number. The Philips UFS takes an image of the label, the whole slide image and composite high resolution images. The barcode on the slide is read by the software and used to identify the slide in the database. If the barcode is not available or cannot be read, an image is classified as ‘Action Required’ and placed in a dedicated folder in the Philips IMS with the same name. If an image is placed in that folder, a user can manually enter the SlideID and retry communication with LIS. The label image is by default visible in the IMS web viewer but it is the user’s preference to show or hide the label image.

# 5. Specimen Sampling and Handling:

The Philips UFS has the capacity to automatically scan 300 slides per run (15 glass slide racks with up to 20 slides per rack). The user may change the priority of the slide scanning sequence using the touch screen display. The display also shows the scanning status of each rack.

6. Calibration:

Calibrations, both manual and automated, are performed during production, system installation, operation and maintenance over the lifetime of the product.

Calibration at installation: A full calibration of the Philips UFS is performed during production at the factory using a service application. The same service application is used by service engineers to re-calibrate the Philips UFS after system installation. It includes calibration of: color (using a color target and transformation matrix), homogeneity of the illumination, alignment of mechatronics elements of the Philips UFS (e.g. stage, slide gripper), and alignment of positions of all cameras (snapshot, autofocus and line-scan-color cameras (Red, Green and Blue)).

Calibration during operation: During normal operation, the Philips UFS automatically recalibrates itself periodically for the following elements: stages, focus system, line scan cameras, and homogeneity of the illumination. While scanning, the Philips UFS continuously monitors the quality of each lane and re-scans a lane when the quality is insufficient. A user can manually start calibration process via user interface of the Philips UFS. At least every six months, the service engineer should use the same service application used during production and installation to re-calibrate the Philips UFS.

7. Quality Control:

The accuracy of the system depends on the laboratory following the quality control instructions for the Dako HercepTest™.

8. Software:

FDA has reviewed applicant’s Hazard Analysis and Software Development processes for this line of product types:

Yes___X_ _ or No_

# F. Regulatory Information:

1. Regulation section: 21 CFR $\ S 8 6 4 . 1 8 6 0$ , Immunohistochemistry reagents and kits

2. Classification: Class II

3 Product code:

OEO (Microscope, Automated, Digital Image, Manual Interpretation)

4. Panel: Pathology 88

# G. Intended Use:

1. Indication(s) for Use:

The Philips HER2/neu IHC Digital Manual Read is intended for in vitro diagnostic use as an aid to the pathologist in the display, detection, counting and classification of tissues and cells of clinical interest based on particular color, intensity, size, pattern and shape. The Philips HER2/neu IHC Digital Manual Read is based on the Philips Digital Pathology Solution platform, which is an automated digital slide creation, management, viewing and analysis system.

The Philips HER2/neu IHC Digital Manual Read is intended for use as an accessory to the Dako HercepTest™ to aid in the detection and semiquantitative measurement of HER2/neu (c-erbB-2) in formalin-fixed, paraffinembedded neoplastic tissue immunohistochemically stained for HER-2 receptors on a computer monitor. When used with the Dako HercepTest™, it is indicated for use as an aid in the assessment of breast cancer patients from whom HERCEPTIN $^ \mathrm { \textregistered }$ (Trastuzumab) treatment is being considered. Note: The actual correlation of the Dako HercepTest™ to Herceptin $^ \mathrm { \textregistered }$ clinical outcome has not been established.

Note: The Philips HER2/neu IHC Digital Manual Read is for evaluation of digital images of immunohistochemically stained slides that would otherwise be appropriate for manual visualization by conventional microscopy. It is the responsibility of a qualified pathologist to employ appropriate morphological studies and controls as specified in the instructions for Dako HercepTest™ to assure the validity of the scores obtained using Philips HER2/neu IHC Digital Manual Read.

2. Special Conditions for Use Statement(s): For Prescription Use Only.

# H. Substantial Equivalence Information:

1. Predicate Device Name(s) and 510(k) numbers:

Olympus Virtual Slide System, VS800 System, k111914

2. Comparison with Predicate Device:

<table><tr><td rowspan=1 colspan=3>Similarities</td></tr><tr><td rowspan=1 colspan=1>Item</td><td rowspan=1 colspan=1>Device</td><td rowspan=1 colspan=1>Predicate</td></tr><tr><td rowspan=1 colspan=1>Intended Use</td><td rowspan=1 colspan=1>Semi-quantitativeinterpretation of HER2</td><td rowspan=1 colspan=1>Same</td></tr><tr><td rowspan=1 colspan=1>Assay</td><td rowspan=1 colspan=1>Dako HercepTestTM</td><td rowspan=1 colspan=1>Same</td></tr><tr><td rowspan=1 colspan=1>Specimen Type</td><td rowspan=1 colspan=1>Formalin-fixed paraffinembedded human breastcancer</td><td rowspan=1 colspan=1>Same</td></tr><tr><td rowspan=1 colspan=1>Method ofInterpretation</td><td rowspan=1 colspan=1>Manual</td><td rowspan=1 colspan=1>Manual</td></tr></table>

<table><tr><td rowspan=1 colspan=3>Differences</td></tr><tr><td rowspan=1 colspan=1>Item</td><td rowspan=1 colspan=1>Device</td><td rowspan=1 colspan=1>Predicate</td></tr><tr><td rowspan=1 colspan=1>Camera</td><td rowspan=1 colspan=1>3 Cameras (RGB)</td><td rowspan=1 colspan=1>CCD camera</td></tr><tr><td rowspan=1 colspan=1>Image acquisition</td><td rowspan=1 colspan=1>Line scanning</td><td rowspan=1 colspan=1>Tile stitching</td></tr><tr><td rowspan=1 colspan=1>Device Components</td><td rowspan=1 colspan=1>Automated scanner andsoftware, monitor andcomputer</td><td rowspan=1 colspan=1>Scanner, computer,color monitor,keyboard, scannersoftware and digitalpathology informationmanagement software</td></tr></table>

# I. Special Control/Guidance Document Referenced (if applicable):

Guidance for Off-the-Shelf Software Use in Medical Devices (Sept. 1999)

Guidance for the Content of Premarket Submissions for Software Contained in Medical Devices (May 2005)

Cybersecurity for Networked Medical Devices Containing Off-the-Shelf Software Jan. 2005)

Format for Traditional and Abbreviated 510(k)s (Aug 2005)

General Principles of Software Validation; Final Guidance for Industry and Staff (Jan 2002)

Medical Device Use –Safety: Incorporating Human Factors Engineering into Risk Management (July 2000)

Guidance for In Vitro Diagnostic (IVD) Device Studies – Frequently Asked Questions (June 25, 2010)

# J. Performance Characteristics:

1. Analytical Performance:

a. Accuracy:

A method comparison study was conducted to compare traditional optical microscopy (“Manual Optical”) and manual reading of digital slides on a computer monitor (“Manual Digital”) with breast cancer specimens that were stained with Dako HercepTest™.

A total of two hundred (200) formalin-fixed, paraffin-embedded breast tissue specimens from a tissue bank of de-identified human specimens were selected for inclusion in the study. The slides were prescreened by a pathologist to evaluate the quality of the tissue, quality of the staining and to provide a score. Slides that passed the prescreening were randomly selected to fulfill a roughly equal distribution of HercepTest™ scores in four categories $( 0 , 1 + , 2 + , 3 + )$ .

The pathologists in the study were trained in the use of the investigational device according to the labeling. The slides were scanned at three different scanners and three pathologists from two sites participated in the study. The order of the methods was randomized over the pathologists and the washout period between reads was at least 7 days.

Tables 1-3 show the $4 \mathrm { x } 4$ tables for the agreements between the manual microscopy reads and manual digital reads using column-wise Percent Agreement (PA; i.e., percent of manual digital reads that agree with a given manual optical read) with an Exact $9 5 \%$ Confidence Interval (CI) for each of the pathologists. The statistical analysis is provided for a trichotomous agreement of the HER2 scores combining 0 and $1 + _ { _ { \cdot } }$ , and leaving $^ { 2 + }$ and $^ { 3 + }$ uncombined. For example, there were 93 $( 3 8 + 5 5 )$ slides with manual optical read either 0 or $1 +$ and 85 $( 3 7 + 1 + 1 + 4 6 )$ of these were called 0 or $1 +$ by manual digital read, resulting in a PA of $9 1 . 3 9 \%$ (85/93).

Table 1: Manual Optical Reads vs. Manual Digital Reads 4x4 Tables for Site 1-Pathologist 1   

<table><tr><td rowspan=2 colspan=2>Pathologist 1</td><td rowspan=1 colspan=5>Manual Optical Read</td></tr><tr><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1+</td><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>TOTAL</td></tr><tr><td rowspan=5 colspan=1>ManualDigitalRead</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>37</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>38</td></tr><tr><td rowspan=1 colspan=1>1+</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>46</td><td rowspan=1 colspan=1>8</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>55</td></tr><tr><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>8</td><td rowspan=1 colspan=1>33</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>42</td></tr><tr><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>5</td><td rowspan=1 colspan=1>44</td><td rowspan=1 colspan=1>49</td></tr><tr><td rowspan=1 colspan=1>TOTAL</td><td rowspan=1 colspan=1>38</td><td rowspan=1 colspan=1>55</td><td rowspan=1 colspan=1>46</td><td rowspan=1 colspan=1>45</td><td rowspan=1 colspan=1>199</td></tr></table>

Table 2: Manual Optical Reads vs. Manual Digital Reads 4x4 Tables for Site 1-Pathologist 2   

<table><tr><td rowspan=1 colspan=1>Score</td><td rowspan=1 colspan=1>PA</td><td rowspan=1 colspan=1>Exact 95% CI</td></tr><tr><td rowspan=1 colspan=1>01+</td><td rowspan=1 colspan=1>91.40%</td><td rowspan=1 colspan=1>83.75%,96.21%</td></tr><tr><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>71.74%</td><td rowspan=1 colspan=1>56.54%,84.01%</td></tr><tr><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>97.78%</td><td rowspan=1 colspan=1>88.23%, 99.94%</td></tr></table>

<table><tr><td rowspan=2 colspan=2>Pathologist 2</td><td rowspan=1 colspan=5>Manual Optical Read</td></tr><tr><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1+</td><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>TOTAL</td></tr><tr><td rowspan=5 colspan=1>ManualDigitalRead</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>23</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>23</td></tr><tr><td rowspan=1 colspan=1>1+</td><td rowspan=1 colspan=1>22</td><td rowspan=1 colspan=1>21</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>44</td></tr><tr><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>2</td><td rowspan=1 colspan=1>28</td><td rowspan=1 colspan=1>45</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>75</td></tr><tr><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>5</td><td rowspan=1 colspan=1>43</td><td rowspan=1 colspan=1>48</td></tr><tr><td rowspan=1 colspan=1>TOTAL</td><td rowspan=1 colspan=1>47</td><td rowspan=1 colspan=1>49</td><td rowspan=1 colspan=1>51</td><td rowspan=1 colspan=1>43</td><td rowspan=1 colspan=1>190</td></tr></table>

Table 3: Manual Optical Reads vs. Manual Digital Reads 4x4 Tables for Site 2-Pathologist 3   

<table><tr><td rowspan=1 colspan=1>Score</td><td rowspan=1 colspan=1>PA</td><td rowspan=1 colspan=1>Exact 95% CI</td></tr><tr><td rowspan=1 colspan=1>$01+</td><td rowspan=1 colspan=1>68.75%</td><td rowspan=1 colspan=1>58.48%, 77.82%</td></tr><tr><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>88.24%</td><td rowspan=1 colspan=1>76.13%,95.56%</td></tr><tr><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>100.0%</td><td rowspan=1 colspan=1>91.78%, 100.0%</td></tr></table>

<table><tr><td rowspan=2 colspan=2>Pathologist 3</td><td rowspan=1 colspan=5>Manual Optical Read</td></tr><tr><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1+</td><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>TOTAL</td></tr><tr><td rowspan=5 colspan=1>ManualDigitalRead</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>26</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>26</td></tr><tr><td rowspan=1 colspan=1>1+</td><td rowspan=1 colspan=1>6</td><td rowspan=1 colspan=1>77</td><td rowspan=1 colspan=1>2</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>85</td></tr><tr><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>13</td><td rowspan=1 colspan=1>28</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>42</td></tr><tr><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>0</td><td rowspan=1 colspan=1>1</td><td rowspan=1 colspan=1>10</td><td rowspan=1 colspan=1>32</td><td rowspan=1 colspan=1>43</td></tr><tr><td rowspan=1 colspan=1>TOTAL</td><td rowspan=1 colspan=1>32</td><td rowspan=1 colspan=1>91</td><td rowspan=1 colspan=1>40</td><td rowspan=1 colspan=1>33</td><td rowspan=1 colspan=1>199</td></tr></table>

<table><tr><td rowspan=1 colspan=1>Score</td><td rowspan=1 colspan=1>PA</td><td rowspan=1 colspan=1>Exact 95% CI</td></tr><tr><td rowspan=1 colspan=1>$01+</td><td rowspan=1 colspan=1>88.62%</td><td rowspan=1 colspan=1>81.64%, 93.64%</td></tr><tr><td rowspan=1 colspan=1>2+</td><td rowspan=1 colspan=1>70.00%</td><td rowspan=1 colspan=1>53.47%,83.44%</td></tr><tr><td rowspan=1 colspan=1>3+</td><td rowspan=1 colspan=1>96.97%</td><td rowspan=1 colspan=1>84.24%, 99.92%</td></tr></table>

b. Precision/Reproducibility:

Intra-Pathologist

A slide set of eight (8) slides, consisting of two slides in each of the categories $( 0 , 1 + , 2 + , 3 + )$ , was used in the intra-pathologist study. Twelve additional “wild card” slides were added to minimize recall bias. These 12 slides were not used in the analyses. Each slide was read 5 times for a total of 40 reads by both the optical and digital method. For the intrapathologist study outliers are defined as scores that are different from the median values of the scores provided by the pathologist over 5 runs of the method. For manual optical reads intra-pathologist agreement was $8 7 . 5 \%$ (35/40). For manual digital reads intra-pathologist agreement was $9 2 . 5 \%$ (37/40).

# Inter-Pathologist Precision

The inter-pathologist study used data collected from all sites for each of the 3 pathologists in the method comparison study $\scriptstyle ( \mathrm { N } = 1 9 1$ ). For manual digital reads using binary percent agreement $\left. 0 , 1 + \mathrm { v s } . 2 + , 3 + \right)$ interpathologist agreement was $8 0 . 4 5 \%$ with Exact $9 5 \%$ CI $7 6 . 2 7 \%$ , $8 4 . 6 4 \%$ ). For manual optical reads inter-pathologist agreement was $7 7 . 6 6 \%$ with $9 5 \%$ Exact CI ( $7 3 . 1 2 \%$ , $8 2 . 2 0 \%$ ).

Inter-Day/Intra-System and Inter-System Precision

A study was conducted at one clinical site to assess the inter-day/intrainstrument and inter-instrument precision for manual digital reads.

A subset of forty (40) slides from the method comparison study was used. The slides were selected to provide an equal distribution of HER2 scores in the four scoring categories $( 0 , 1 + , 2 + , 3 + )$ . For the Inter-Day/IntraSystem study the slide set was scanned on three different days on the same device and the images were scored by one pathologist. For the InterSystem study the slides set was scanned one time on three devices and the images were scored by a second pathologist. To prevent recall bias, slides were randomized between reads and a minimum washout period of one week was required between reading sessions. Additionally, 32 wild card images, not included in the analysis were utilized to confound the reads.

The statistical analysis is presented across all slides, with pair-wise comparisons of all reads by the pathologist, using Percent Agreement (PA) with a $9 5 \%$ Confidence Interval (CI). The statistical analysis is provided for a trichotomous categorization of the HER2 scores combined 0 and $1 +$ and leaving $^ { 2 + }$ and $^ { 3 + }$ uncombined.

<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>PA</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Manual Digital Reads - Inter-Day/Intra-System</td><td rowspan=1 colspan=1>92.98%</td><td rowspan=1 colspan=1>(86.76, 96.40)</td></tr><tr><td rowspan=1 colspan=1>Manual Digital Reads - Inter-System</td><td rowspan=1 colspan=1>88.24%</td><td rowspan=1 colspan=1>(80.55, 93.14)</td></tr></table>

c. Linearity: Not applicable.   
d. Carryover: Not applicable.   
e. Interfering Substances: Not applicable.

2. Other Supportive Instrument Performance Data Not Covered Above:

The Philips UFS automatically recalibrates itself periodically for the following elements: stages, focus system, line scan cameras, and homogeneity of the illumination. Calibration is preceded by a measurement of system parameters which is performed in a certain interval. The interval is defined based on the number of slides scanned, temperature or time. If the parameters are found to have drifted outside their prescribed range, a corresponding calibration is performed to bring them back within the range. Then the parameters are measured again to verify their status. Intervals for auto-calibration are presented in Table 6.

Table 6: UFS Auto-calibration intervals for focus system, line scan cameras (LNCRs) and illumination homogeneity   

<table><tr><td rowspan=1 colspan=3>Auto-Calibration</td></tr><tr><td rowspan=1 colspan=1>Stage to LNCRCalibration</td><td rowspan=1 colspan=1>Startup200 slides4 hours2°</td><td rowspan=1 colspan=1>25 slides1 hour</td></tr><tr><td rowspan=1 colspan=1>Focus SystemCalibration</td><td rowspan=1 colspan=1>Startup200 slides4 hours2</td><td rowspan=1 colspan=1>25 slides1 hours</td></tr><tr><td rowspan=1 colspan=1>LNCR Homogeneity</td><td rowspan=1 colspan=1>Startup1 hour0.5°C</td><td rowspan=1 colspan=1>1 hour</td></tr><tr><td rowspan=1 colspan=1>SNCR BackgroundCalibration</td><td rowspan=1 colspan=1>Startup4 hours2°</td><td rowspan=1 colspan=1>1 slide1 hours</td></tr></table>

# K. Proposed Labeling:

The labeling is sufficient and it satisfies the requirements of 21 CFR Part 809.10.

# L. Conclusion:

The submitted information in this premarket notification is complete and supports a substantial equivalence decision.