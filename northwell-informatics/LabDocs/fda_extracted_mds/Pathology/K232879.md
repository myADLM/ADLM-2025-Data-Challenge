Ventana Medical Systems, Inc.   
Cameron Smith   
Regulatory Affairs Manager   
(Ventana, VMSI, Roche Tissue Diagnostics, RTD) 1910 E. Innovation Park Drive   
Tucson, Arizona 85755

Re: K232879 Trade/Device Name: Roche Digital Pathology Dx (VENTANA DP 200) Regulation Number: 21 CFR 864.3700 Regulation Name: Whole slide imaging system Regulatory Class: Class II Product Code: PSY Dated: September 15, 2023 Received: September 18, 2023

Dear Cameron Smith:

We have reviewed your section $5 1 0 ( \mathrm { k } )$ premarket notification of intent to market the device referenced above and have determined the device is substantially equivalent (for the indications for use stated in the enclosure) to legally marketed predicate devices marketed in interstate commerce prior to May 28, 1976, the enactment date of the Medical Device Amendments, or to devices that have been reclassified in accordance with the provisions of the Federal Food, Drug, and Cosmetic Act (the Act) that do not require approval of a premarket approval application (PMA). You may, therefore, market the device, subject to the general controls provisions of the Act. Although this letter refers to your product as a device, please be aware that some cleared products may instead be combination products. The 510(k) Premarket Notification Database available at https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm identifies combination product submissions. The general controls provisions of the Act include requirements for annual registration, listing of devices, good manufacturing practice, labeling, and prohibitions against misbranding and adulteration. Please note: CDRH does not evaluate information related to contract liability warranties. We remind you, however, that device labeling must be truthful and not misleading.

If your device is classified (see above) into either class II (Special Controls) or class III (PMA), it may be subject to additional controls. Existing major regulations affecting your device can be found in the Code of Federal Regulations, Title 21, Parts 800 to 898. In addition, FDA may publish further announcements concerning your device in the Federal Register.

Additional information about changes that may require a new premarket notification are provided in the FDA guidance documents entitled "Deciding When to Submit a 510(k) for a Change to an Existing Device"

(https://www.fda.gov/media/99812/download) and "Deciding When to Submit a 510(k) for a Software Change to an Existing Device" (https://www.fda.gov/media/99785/download).

Your device is also subject to, among other requirements, the Quality System (QS) regulation (21 CFR Part 820), which includes, but is not limited to, 21 CFR 820.30, Design controls; 21 CFR 820.90, Nonconforming product; and 21 CFR 820.100, Corrective and preventive action. Please note that regardless of whether a change requires premarket review, the QS regulation requires device manufacturers to review and approve changes to device design and production (21 CFR 820.30 and 21 CFR 820.70) and document changes and approvals in the device master record (21 CFR 820.181).

Please be advised that FDA's issuance of a substantial equivalence determination does not mean that FDA has made a determination that your device complies with other requirements of the Act or any Federal statutes and regulations administered by other Federal agencies. You must comply with all the Act's requirements, including, but not limited to: registration and listing (21 CFR Part 807); labeling (21 CFR Part 801 and Part 809); medical device reporting (reporting of medical device-related adverse events) (21 CFR Part 803) for devices or postmarketing safety reporting (21 CFR Part 4, Subpart B) for combination products (see https://www.fda.gov/combination-products/guidance-regulatory-information/postmarketing-safetyreporting-combination-products); good manufacturing practice requirements as set forth in the quality systems (QS) regulation (21 CFR Part 820) for devices or current good manufacturing practices (21 CFR Part 4, Subpart A) for combination products; and, if applicable, the electronic product radiation control provisions (Sections 531-542 of the Act); 21 CFR Parts 1000-1050.

Also, please note the regulation entitled, "Misbranding by reference to premarket notification" (21 CFR 807.97). For questions regarding the reporting of adverse events under the MDR regulation (21 CFR Part 803), please go to https://www.fda.gov/medical-devices/medical-device-safety/medical-device-reportingmdr-how-report-medical-device-problems.

For comprehensive regulatory information about medical devices and radiation-emitting products, including information about labeling regulations, please see Device Advice (https://www.fda.gov/medical  
devices/device-advice-comprehensive-regulatory-assistance) and CDRH Learn   
(https://www.fda.gov/training-and-continuing-education/cdrh-learn). Additionally, you may contact the Division of Industry and Consumer Education (DICE) to ask a question about a specific regulatory topic. See the DICE website (https://www.fda.gov/medical-devices/device-advice-comprehensive-regulatoryassistance/contact-us-division-industry-and-consumer-education-dice) for more information or contact DICE by email (DICE@fda.hhs.gov) or phone (1-800-638-2041 or 301-796-7100).

# Sincerely, Shyam Kalavar -S

Shyam Kalavar   
Deputy Branch Chief   
Division of Molecular Genetics and Pathology 2   
OHT7: Office of In Vitro Diagnostics   
Office of Product Evaluation and Quality   
Center for Devices and Radiological Health

Enclosure

510(k) Number (if known) K232879

Device Name Roche Digital Pathology Dx (VENTANA DP 200)

Indications for Use (Describe)   
Roche Digital Pathology Dx (VENTANA DP 200) is an automated digital slide creation, viewing and management system. Roche Digital Pathology Dx (VENTANA DP 200) is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of scanned pathology slides prepared from formalin-fixed paraffinembedded (FFPE) tissue. Roche Digital Pathology Dx (VENTANA DP 200) is not intended for use with frozen section, cytology, or non-FFPE hematopathology specimens. Roche Digital Pathology Dx (VENTANA DP 200) is for creation and viewing of digital images of scanned glass slides that would otherwise be appropriate for manual visualization by conventional light microscopy.

Roche Digital Pathology Dx (VENTANA DP 200) is composed of VENTANA DP 200 slide scanner, Roche uPath enterprise software, and the ASUS PA248QV display. It is the responsibility of a qualified pathologist to employ appropriate procedures and safeguards to assure the validity of the interpretation of images obtained using Roche Digital Pathology Dx (VENTANA DP 200).

This section applies only to requirements of the Paperwork Reduction Act of 1995.

# \*DO NOT SEND YOUR COMPLETED FORM TO THE PRA STAFF EMAIL ADDRESS BELOW.\*

The burden time for this collection of information is estimated to average 79 hours per response, including the time to review instructions, search existing data sources, gather and maintain the data needed and complete and review the collection of information. Send comments regarding this burden estimate or any other aspect of this information collection, including suggestions for reducing this burden, to:

Department of Health and Human Services Food and Drug Administration Office of Chief Information Officer Paperwork Reduction Act (PRA) Staff PRAStaff@fda.hhs.gov

“An agency may not conduct or sponsor, and a person is not required to respond to, a collection of information unless it displays a currently valid OMB number.”

# 510(k) Summary Roche Digital Pathology Dx (VENTANA DP 200)

Date Prepared: June 14, 2024

# SUBMITTER

Ventana Medical Systems, Inc.

# CONTACT PERSON

Ventana Medical Systems, Inc.   
Cameron Smith   
Regulatory Affairs Manager   
(Ventana, VMSI, Roche Tissue Diagnostics, RTD) 1910 E. Innovation Park Drive   
Tucson, Arizona 85755

# DEVICE INFORMATION

# Subject Device

Proprietary Name: Common Name: Classification Name: Regulation Section: Regulatory Product Code: Review Panel: 510(k) Number:

Roche Digital Pathology Dx (VENTANA DP 200)   
VENTANA DP 200   
Whole Slide Imaging System   
21 CFR 864.3700   
Classification: Class II   
PSY   
88 – Pathology   
K232879

# Predicate Device

Proprietary Name: Aperio AT2 DX System Submission Number: K190332

# I. INTENDED USE

Roche Digital Pathology Dx (VENTANA DP 200) is an automated digital slide creation, viewing and management system. Roche Digital Pathology Dx (VENTANA DP 200) is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of scanned pathology slides prepared from formalin-fixed paraffin-embedded (FFPE) tissue. Roche Digital Pathology Dx (VENTANA DP 200) is not intended for use with frozen section, cytology, or non-FFPE hematopathology specimens. Roche Digital Pathology Dx (VENTANA DP 200) is for creation and viewing of digital images of scanned glass slides that would otherwise be appropriate for manual visualization by conventional light microscopy.

Roche Digital Pathology Dx (VENTANA DP 200) is composed of VENTANA DP 200 slide scanner, Roche uPath enterprise software, and ASUS PA248QV display. It is the responsibility of a qualified pathologist to employ appropriate procedures and safeguards to assure the validity of the interpretation of images obtained using Roche Digital Pathology Dx (VENTANA DP 200).

# II. DEVICE DESCRIPTION

Roche Digital Pathology Dx (VENTANA DP 200), hereinafter referred to as Roche Digital Pathology Dx, is a whole slide imaging (WSI) system. It is an automated digital slide creation, viewing, and management system intended to aid pathologists in generating, reviewing, and interpreting digital images of surgical pathology slides that would otherwise be appropriate for manual visualization by conventional light microscopy. Roche Digital Pathology Dx system is composed of the following components:

● VENTANA DP 200 slide scanner   
● Roche uPath enterprise software 1.1.1 (hereinafter, “uPath”)   
● ASUS PA248QV display

VENTANA DP 200 slide scanner is a bright-field digital pathology scanner that accommodates loading and scanning of up to 6 standard slides. The scanner comprises a high-resolution $2 0 \mathrm { x }$ objective with the ability to scan at both $2 0 \mathrm { x }$ and $4 0 \mathrm { x }$ . With its uniquely designed optics and scanning methods, VENTANA DP 200 scanner enables users to capture sharp, high-resolution digital images of stained tissue specimens on glass slides. The scanner features automatic detection of the tissue specimen on the slide, automated 1D and 2D barcode reading, and selectable volume scanning (3 to 15 focus layers). It also integrates color profiling to ensure that images produced from scanned slides are generated with a color-managed International Color Consortium (ICC) profile. VENTANA DP 200 image files are generated in a proprietary format (BIF) and can be uploaded to an Image Management System (IMS), such as the one provided with Roche uPath enterprise software. Roche uPath enterprise software (uPath), a component of Roche Digital Pathology system, is a web-based image management and workflow software application. uPath enterprise software can be accessed on a Windows workstation using Google Chrome or Microsoft Edge. The interface of uPath software enables laboratories to manage their workflow from the time the digital slide image is produced and acquired by a VENTANA slide scanner through the subsequent processes including, but not limited to, review of the digital image on the monitor screen, analysis, and reporting of results. The software incorporates specific functions for pathologists, laboratory histology staff, workflow coordinators, and laboratory administrators.

# III. COMPARISON OF TECHNOLOGICAL CHARACTERISTICS WITH THE PREDICATE DEVICE

The candidate device, Roche Digital Pathology Dx, is substantially equivalent to the predicate device, Leica Aperio AT2 DX, which was cleared on February 13, 2019 through K190332. Below is a table that provides a comparison between the two devices:

Table 1: Similarities between the Subject Device and the Predicate Device   

<table><tr><td rowspan=1 colspan=1>Item</td><td rowspan=1 colspan=1>Subject Device</td><td rowspan=1 colspan=1>Predicate Device</td></tr><tr><td rowspan=1 colspan=1>Product Name</td><td rowspan=1 colspan=1>Roche Digital Pathology Dx (VENTANA DP 200)</td><td rowspan=1 colspan=1>Aperio AT2 DX System</td></tr><tr><td rowspan=1 colspan=1>510(k) No.</td><td rowspan=1 colspan=1>K232879</td><td rowspan=1 colspan=1>K190332</td></tr><tr><td rowspan=1 colspan=1>Manufacturer</td><td rowspan=1 colspan=1>Ventana Medical Systems, Inc.</td><td rowspan=1 colspan=1>Leica Biosystems Imaging, Inc.</td></tr><tr><td rowspan=1 colspan=1>Intended Use</td><td rowspan=1 colspan=1>Roche Digital Pathology Dx (VENTANA DP 200), is an automated digital slidecreation, viewing and management system. Roche Digital Pathology Dx(VENTANA DP 200) is intended for in vitro diagnostic use as an aid to thepathologist to review and interpret digital images of scanned pathology slidesprepared from formalin-fixed paraffin-embedded (FFPE) tissue. Roche DigitalPathology Dx (VENTANA DP 200) is not intended for use with frozen section,cytology, or non-FFPE hematopathology specimens. Roche Digital PathologyDx (VENTANA DP 200) is for creation and viewing of digital images ofscanned glass slides that would otherwise be appropriate for manualvisualization by conventional light microscopy.Roche Digital Pathology Dx (VENTANA DP 200) is composed of VENTANADP 200 slide scanner, Roche uPath enterprise software, and ASUS PA248QVdisplay. It is the responsibility of a qualified pathologist to employ appropriateprocedures and safeguards to assure the validity of the interpretation ofimages obtained using Roche Digital Pathology Dx (VENTANA DP 200).</td><td rowspan=1 colspan=1>The Aperio AT2 DX System is an automated digital slide creation and viewingsystem. The Aperio AT2 DX System is intended for in vitro diagnostic use asan aid to the pathologist to review and interpret digital images of surgicalpathology slides prepared from formalin-fixed paraffin embedded (FFPE)tissue. The Aperio AT2 DX System is not intended for use with frozen section,cytology, or non-FFPE hematopathology specimens.The Aperio AT2 DX System is composed of the Aperio AT2 DX scanner, theImageScope DX review application and Display. The Aperio AT2 DX Systemis for creation and viewing of digital images of scanned glass slides thatwould otherwise be appropriate for manual visualization by conventional lightmicroscopy. It is the responsibility of a qualified pathologist to employappropriate procedures and safeguards to assure the validity of theinterpretation of images obtained using the Aperio AT2 DX System</td></tr><tr><td rowspan=1 colspan=1>Classification Regulation</td><td rowspan=1 colspan=1>21 CFR 864.3700</td><td rowspan=1 colspan=1>21 CFR 864.3700</td></tr><tr><td rowspan=1 colspan=1>Product Code</td><td rowspan=1 colspan=1>PSY - Whole Slide Imaging System</td><td rowspan=1 colspan=1>PSY - Whole Slide Imaging System</td></tr><tr><td rowspan=1 colspan=1>Classification Panel</td><td rowspan=1 colspan=1>(88) Pathology</td><td rowspan=1 colspan=1>(88) Pathology</td></tr><tr><td rowspan=1 colspan=1>Principle of Operation</td><td rowspan=1 colspan=1>After conducting Quality Control (QC) on the glass slides per laboratorystandards (e.g., staining, coverslipping, barcode placement, etc.), thetechnician loads the slides into VENTANA DP 200 slide scanner. The scannerscans the slides and generates a whole slide image for each slide. Thetechnician performs QC on scanned WSI images by checking image data andimage quality. When QC is failed, the slide will be re-scanned. The acquiredWSI images are stored in an end user provided image storage attached to thelocal network. During review, the pathologist opens WSl images from theimage storage in Roche uPath enterprise software, performs further QC toensure image quality, and reads the WSl images of the slides to make adiagnosis.</td><td rowspan=1 colspan=1>After conducting Quality Control (QC) on the glass slides per laboratorystandards (e.g., staining, coverslipping, barcode placement, etc.), thetechnician loads the slides into the Aperio AT2 DX scanner. The scannerscans the slides and generates WSl images for each slide. The technicianperforms QC on scanned WSl images by checking image data and imagequality. When QC is failed, the slide will be re-scanned. The acquired WSIimages are stored in an end user provided image storage attached to thelocal network. During review, the pathologist opens WSl images acquired withthe Aperio AT2 DX scanner from the image storage, performs further QC toensure image quality and reads WSl images of the slides to make adiagnosis.</td></tr><tr><td rowspan=1 colspan=1>Device Components</td><td rowspan=1 colspan=1>WSI scanner (VENTANA DP 200 slide scanner), Image Management System(Roche uPath enterprise software), and color monitor display</td><td rowspan=1 colspan=1>WSI scanner (Aperio AT2 DX scanner), Image Management System(ImageScope DX application), and color monitor display</td></tr></table>

Table 2: Differences between the Subject Device and the Predicate Device   

<table><tr><td rowspan=1 colspan=1>Item</td><td rowspan=1 colspan=1>Subject Device</td><td rowspan=1 colspan=1>Predicate Device</td></tr><tr><td rowspan=1 colspan=1>Product Name</td><td rowspan=1 colspan=1>Roche Digital Pathology Dx(VENTANA DP 200)</td><td rowspan=1 colspan=1>Aperio AT2 DX System</td></tr><tr><td rowspan=1 colspan=1>510(k) No.</td><td rowspan=1 colspan=1>K232879</td><td rowspan=1 colspan=1>K190332</td></tr><tr><td rowspan=1 colspan=1>Whole Slide Imaging Scanner</td><td rowspan=1 colspan=1>VENTANA DP 200; 6 slides</td><td rowspan=1 colspan=1>Aperio AT2 DX; 400 slides</td></tr><tr><td rowspan=1 colspan=1>Review Software</td><td rowspan=1 colspan=1>Roche uPath</td><td rowspan=1 colspan=1>ImageScope DX</td></tr><tr><td rowspan=1 colspan=1>Monitor Display</td><td rowspan=1 colspan=1>ASUS PA248QV</td><td rowspan=1 colspan=1>Dell MR2416</td></tr></table>

There are no differences between the candidate and predicate device that impact safety or effectiveness, or raise any new questions of those aspects, as all candidate components have been qualified & validated for sufficient use as a whole slide imaging system.

# IV. PERFORMANCE DATA

# 1. Technical Studies

Multiple studies were conducted to evaluate the performance assessment data associated with the technical evaluation of Roche Digital Pathology Dx.

# A. Slide Feeder

Information was provided on the configuration of the slide feed mechanism, including a physical description of the slide, the number of slides in queue (carrier), and the class of automation. Information was provided on the user interaction with the slide feeder, including hardware, software, feedback mechanisms, and Failure Mode and Effects Analysis (FMEA).

# B. Light Source

Descriptive information associated with the lamp and the condenser was provided. Testing information was provided to verify the spectral distribution of the light source as part of the color reproduction capability of VENTANA DP 200 scanner.

# C. Imaging Optics

An optical schematic with all optical elements identified from slide (object plane) to digital image sensor (image plane) was provided. Descriptive information regarding the microscope objective, the auxiliary lenses, and the magnification of imaging optics was provided. Testing

information regarding the relative irradiance, optical distortions, and lateral chromatic aberrations was provided.

# D. Focus System

Schematic diagrams and a description of operation of the focus system, which includes the optical system, 2 imaging cameras, and a focus tracking algorithm, was provided.

# E. Mechanical Scanner Movement

Information and specifications on the configuration of the stage, method of movement, control of movement of the stage, and FMEA was provided. Test data to verify the repeatability of the stage movement mechanism staying within limit during operation was provided.

# F. Digital Imaging Sensor

Information and specifications on the sensor type, pixel information, responsivity specifications, noise specifications, readout rate, and digital output format was provided. Test data to determine the correct functioning of the digital image sensor that converts optical signals of the slide to digital signals which consist of a set of numerical values corresponding to the brightness and color at each point in the optical image was provided.

# G. Image Processing Software

Information and specifications on exposure control, white balance, color correction, subsampling, pixel-offset correction, pixel-gain or flat-field correction, and pixel-defect correction were provided.

# H. Image Composition

Information and specifications on the scanning method, the scanning speed, and the number of planes at the Z-axis to be digitized were provided. Test data to analyze the image composition performance was provided.

# I. Image Files Format

Information and specifications on the compression method, compression ratio, file format, and file organization were provided.

# J. Image Review Manipulation Software

Information and specifications on continuous panning and pre-fetching, continuous zooming, discrete $Z .$ -axis displacement, the ability to compare multiple slides simultaneously on multiple windows, image enhancement and sharpening functions, color manipulation, annotation tools, and digital bookmarks were provided.

# K. Computer Environment

Information and specifications on the computer hardware, operating system, graphics card, graphics card driver, color management settings, color profile, and display interface were provided.

# L. Display

Information and specifications on the technological characteristics of the display such as pixel density, aspect ratio, display viewing area, display surface, backlight type, panel type, viewing angle, pixel pitch, resolution , color space, max brightness, contrast ratio, response time, refresh rate (max), color accuracy, color adjustment, gamma adjustment, adjustments, display interface, and certificate were provided. Test data to verify the performance of the display for user controls, spatial resolution, pixel defects (count and map), artifacts, temporal response, maximum and minimum luminance (achievable and recommended), grayscale, luminance uniformity, bidirectional reflection distribution function, gray tracking, color scale, and color gamut volume was provided.

# M. Color Reproducibility

Test data to evaluate the color reproducibility of the system was provided.

# N. Spatial Resolution

Test data to evaluate the composite optical performance of all components in the image acquisition phase was provided.

# O. Focusing test

Test data to evaluate the technical focus quality of the system was provided.

# P. Whole Slide Tissue Coverage

Test data to demonstrate that the entire tissue specimen on the glass slide is detected by the tissue detection algorithms and that all the tissue specimens are included in the digital image file was provided.

# Q. Stitching Error

Test data to evaluate the stitching errors and artifacts in the reconstructed image was provided.

# R. Turnaround Time

Test data to evaluate the turnaround time of the system was provided.

# S. User Interface

Information on the parts of the system that users interact with, along with human factors/usability validation testing performed to demonstrate that representative users of the WSI system can perform essential tasks and those critical to safety under simulated use conditions was provided.

# 2. User Interface/Human Factors Validation

Human factors studies designed to assess performance of critical user tasks and use scenarios by representative users, including anatomic pathology lab technicians and pathologists, were conducted. Information provided included a list of all critical user tasks and a description of the process that was followed. A systematic evaluation of simulated use by representative participants (17 technicians and 18 pathologists) performing all tasks (including critical tasks) required for operation of the system, and subjective assessment of potential failure modes was provided. All participants were able to perform all tasks (including the critical tasks), and no critical task failures were observed. There were some occasional difficulties that are generally expected with any new system with software and instrument(s), but the system’s learnability and ease of use appeared to be sufficient. All user difficulties observed in the studies had minimal impact on the perception of the usability, and no difficulties or failures were observed performing tasks that could lead to permanent or serious patient harm. In all instances, both pathologists and histopathology technicians were able to identify cases and ensure that all information needed to perform primary diagnosis was available and accessible.

# 3. Electromagnetic Compatibility (EMC) Testing

VENTANA DP 200 EMC testing was performed by external vendor Intertek testing services using the following test standards: EN 61326-1:2013, EN 61326-2-6:2013, EN 61000-3- 2:2014 and EN 61000-3-3:2013. According to the Intertek test report, the emission testing was performed in accordance with EN 55011:2009 +A1:2010 and VENTANA DP 200 met the testing requirements classified for Group 1, Class A equipment. VENTANA DP 200 device also passed the various immunity testing categories based on the corresponding test standards.

# 4. Clinical Testing

# A. Clinical Accuracy Study

A multi-center study was conducted to demonstrate that viewing, reviewing, and diagnosing digital images of surgical pathology FFPE tissue slides using Roche Digital Pathology Dx (VENTANA DP 200) system is non-inferior to using traditional optical (light) microscopy. The primary endpoint was the difference in agreement rates between diagnoses rendered using Roche’s digital WSI review modality (digital read [DR]) and the manual microscopy slide review modality (manual read [MR]) when each was compared to the reference diagnosis, which was based on the original sign-out pathologic diagnosis rendered at the study sites using an optical (light) microscope.

Four sites were used in the study. Two Screening Pathologists at each study site pre-screened cases from that site for possible inclusion in the study by reviewing their clinical database of archived specimens. Cases were identified sequentially (chronologically or reverse chronologically) with a minimum of one year between the date of sign-out diagnosis and beginning of the study. The first Screening Pathologist reviewed all available H&E and ancillary stained slides (i.e., immunohistochemistry and special stains) for each case using manual microscopy to determine whether the case met the study inclusion/exclusion criteria. By reviewing the microscopic slides used to make the sign-out diagnosis, the slide(s) that were representative of the sign-out diagnosis for the case were identified. The Screening Pathologist confirmed the diagnosis related to that particular case by microscopically evaluating the H&E and any ancillary stained slides along with the relevant clinical information as extracted from the sign-out report.

Once the case slides were reviewed and selected by the first Screening Pathologist, the signout diagnosis report data captured was verified by a second Screening Pathologist to confirm the diagnostic accuracy of the case and whether the case met the study inclusion/exclusion criteria.

Across 4 sites, a total of 2047 cases (a total of 3259 slides) consisting of multiple organ and tissue types were enrolled. At each site, all 4 Reading Pathologists read all the cases enrolled at that site using both MR and DR modalities in an alternating fashion and randomized order and with a washout period of at least 30 days between the MR and DR diagnoses, resulting in an expected total of 8188 DR diagnoses and 8188 MR diagnoses, or 16376 total diagnoses.

The 16 Reading Pathologists were provided with all representative slide(s) for each case at the same time, mimicking a practice setting. An electronic case report form (eCRF) was completed to document each Reading Pathologist’s diagnosis. For a given case, up to 3 Adjudication Pathologists were assigned to review the Reading Pathologists’ diagnoses that were rendered using MR and DR compared against the corresponding sign-out diagnoses and determined whether the reader diagnoses agreed with the reference sign-out diagnoses, disagreed with minor differences, or disagreed with major differences. A disagreement with major differences was defined as a difference in diagnosis that would be associated with a clinically important difference in patient management. A disagreement with minor differences was defined as a difference in diagnosis that would not be associated with a clinically important difference in patient management. First, 2 Adjudication Pathologists (adjudicators) separately assessed each Reading Pathologist’s primary diagnosis evaluation for a case against the case’s original sign-out diagnosis while blinded to site, Reading Pathologist’s information, and reading modality (DR or MR). In the event that there was a disagreement between the 2 adjudicators, a third Adjudication Pathologist reviewed the case to achieve majority consensus. In cases where all 3 adjudicators had a different opinion, consensus was arrived at in an adjudication panel meeting consisting of the same 3 Adjudication Pathologists.

The primary objective was to demonstrate the non-inferiority of DR accuracy compared to MR accuracy. Diagnostic accuracy was defined as the agreement between the Reading Pathologist primary diagnoses in each reading mode as compared to the case’s original reference sign-out diagnosis. The primary endpoint was the difference in diagnostic accuracy between DR and MR. The acceptance criterion for this endpoint was based on a hypothesis of non-inferiority. The lower bound of a 2-sided $9 5 \%$ confidence interval for the difference in accuracy (DR – MR) had to be greater than or equal to $- 4 \%$ to declare the DR method to be non-inferior to the MR method. A total of 7562 DR diagnoses paired with 7562 MR diagnoses adjudicated by the adjudication panel had consensus scores and were included in the statistical analyses. The observed overall agreement rate over all sites, Reading Pathologists, and organs, was $9 2 . 0 0 \%$ for DR modality and $9 2 . 6 1 \%$ for MR modality. The DR-MR difference in agreement rate was $- 0 . 6 1 \%$ ( $9 5 \%$ CI: $- 1 . 5 9 \%$ , $0 . 3 5 \%$ ).

In addition to the observed analysis, a Generalized Linear Mixed Model (GLIMMIX) logistic regression was conducted on the Intent to Adjudicate population to demonstrate the noninferiority of the DR agreement rate as compared to the MR agreement rate. For each reading result and reading mode, the dependent variable was the agreement with sign-out diagnosis status. The model accounted for fixed study effects (reading modality and organ type) and random study effects (site and reader nested within site). The agreement rates as estimated by the GLIMMIX logistic model (“Model”) resulted in similar proportions as the study point estimates, i.e., $9 1 . 5 4 \%$ for DR modality and $9 2 . 1 6 \%$ for MR modality. The DR-MR difference in agreement rate was $- 0 . 6 2 \%$ , with 2-sided $9 5 \%$ CI of $[ - 1 . 5 0 \% , 0 . 2 6 \% ]$ . These model results failed to show any statistically significant difference between the 2 reading modalities.

The lower limit of the $9 5 \%$ confidence interval of DR-MR was greater than the pre-specified non-inferiority margin of $- 4 \%$ , and therefore, the DR modality using Roche Digital Pathology Dx was demonstrated to be non-inferior to the MR modality using light microscopy. Thus, the study met the primary objective.

Table 3: Overall Major Discrepancy Rates   

<table><tr><td rowspan=2 colspan=1></td><td rowspan=1 colspan=3>Whole Slide Imaging Review (DR)</td><td rowspan=1 colspan=3>Light Microscope Slide Review (MR)</td><td rowspan=1 colspan=2>Difference (DR - MR)</td></tr><tr><td rowspan=1 colspan=1>TotalReads</td><td rowspan=1 colspan=1>%discordant</td><td rowspan=1 colspan=1>95% CI</td><td rowspan=1 colspan=1>Total Reads</td><td rowspan=1 colspan=1>%discordant</td><td rowspan=1 colspan=1>95% CI</td><td rowspan=1 colspan=1>%discordant</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Observed</td><td rowspan=1 colspan=1>7562</td><td rowspan=1 colspan=1>8.00</td><td rowspan=1 colspan=1>6.73, 9.27</td><td rowspan=1 colspan=1>7562</td><td rowspan=1 colspan=1>7.39</td><td rowspan=1 colspan=1>6.11, 8.78</td><td rowspan=1 colspan=1>0.61</td><td rowspan=1 colspan=1>-0. 35, 1.59</td></tr><tr><td rowspan=1 colspan=1>Model</td><td rowspan=1 colspan=1>7725</td><td rowspan=1 colspan=1>8.46</td><td rowspan=1 colspan=1>7.35, 9.71</td><td rowspan=1 colspan=1>7744</td><td rowspan=1 colspan=1>7.84</td><td rowspan=1 colspan=1>6.80, 9.12</td><td rowspan=1 colspan=1>0.62</td><td rowspan=1 colspan=1>-0.26, 1.50</td></tr></table>

Table 4: Agreement with Sign-Out Diagnosis Rates by Organ   

<table><tr><td rowspan=1 colspan=1>Organ Type</td><td rowspan=1 colspan=1>Digital Read (DR)</td><td rowspan=1 colspan=1>Manual Read (MR)</td><td rowspan=1 colspan=1>Difference inAgreement (DR-MR)</td></tr><tr><td rowspan=1 colspan=1>Anus/ Perianal</td><td rowspan=1 colspan=1>93.0%</td><td rowspan=1 colspan=1>95.7%</td><td rowspan=1 colspan=1>-2.7%</td></tr><tr><td rowspan=1 colspan=1>Appendix</td><td rowspan=1 colspan=1>98.4%</td><td rowspan=1 colspan=1>100.0%</td><td rowspan=1 colspan=1>-1.6%</td></tr><tr><td rowspan=1 colspan=1>Bladder</td><td rowspan=1 colspan=1>85.9%</td><td rowspan=1 colspan=1>87.8%</td><td rowspan=1 colspan=1>-1.8%</td></tr><tr><td rowspan=1 colspan=1>Brain/ Neurological</td><td rowspan=1 colspan=1>94.3%</td><td rowspan=1 colspan=1>92.4%</td><td rowspan=1 colspan=1>1.9%</td></tr><tr><td rowspan=1 colspan=1>Breast</td><td rowspan=1 colspan=1>91.0%</td><td rowspan=1 colspan=1>93.2%</td><td rowspan=1 colspan=1>-2.1%</td></tr><tr><td rowspan=1 colspan=1>Colorectal</td><td rowspan=1 colspan=1>93.2%</td><td rowspan=1 colspan=1>93.0%</td><td rowspan=1 colspan=1>0.2%</td></tr><tr><td rowspan=1 colspan=1>Endocrine</td><td rowspan=1 colspan=1>91.3%</td><td rowspan=1 colspan=1>92.1%</td><td rowspan=1 colspan=1>-0.8%</td></tr><tr><td rowspan=1 colspan=1>GE Junction</td><td rowspan=1 colspan=1>90.7%</td><td rowspan=1 colspan=1>91.5%</td><td rowspan=1 colspan=1>-0.9%</td></tr><tr><td rowspan=1 colspan=1>Gallbladder</td><td rowspan=1 colspan=1>100.0%</td><td rowspan=1 colspan=1>100.0%</td><td rowspan=1 colspan=1>0.0%</td></tr><tr><td rowspan=1 colspan=1>Gynecological</td><td rowspan=1 colspan=1>89.6%</td><td rowspan=1 colspan=1>89.6%</td><td rowspan=1 colspan=1>0.0%</td></tr><tr><td rowspan=1 colspan=1>Hernial/ Peritoneal</td><td rowspan=1 colspan=1>100.0%</td><td rowspan=1 colspan=1>100.0%</td><td rowspan=1 colspan=1>0.0%</td></tr><tr><td rowspan=1 colspan=1>Kidney, Neoplastic</td><td rowspan=1 colspan=1>96.2%</td><td rowspan=1 colspan=1>94.9%</td><td rowspan=1 colspan=1>1.3%</td></tr><tr><td rowspan=1 colspan=1>Liver/ Bile duct, Neoplastic</td><td rowspan=1 colspan=1>97.0%</td><td rowspan=1 colspan=1>98.5%</td><td rowspan=1 colspan=1>-1.5%</td></tr><tr><td rowspan=1 colspan=1>Lung/Bronchus/ Larynx /Oral Cavity/Nasopharynx</td><td rowspan=1 colspan=1>89.4%</td><td rowspan=1 colspan=1>92.3%</td><td rowspan=1 colspan=1>-2.9%</td></tr><tr><td rowspan=1 colspan=1>Lymph Node</td><td rowspan=1 colspan=1>97.1%</td><td rowspan=1 colspan=1>97.8%</td><td rowspan=1 colspan=1>-0.7%</td></tr><tr><td rowspan=1 colspan=1>Prostate</td><td rowspan=1 colspan=1>93.4%</td><td rowspan=1 colspan=1>92.9%</td><td rowspan=1 colspan=1>0.5%</td></tr><tr><td rowspan=1 colspan=1>Salivary Gland</td><td rowspan=1 colspan=1>95.3%</td><td rowspan=1 colspan=1>94.8%</td><td rowspan=1 colspan=1>0.5%</td></tr><tr><td rowspan=1 colspan=1>Skin</td><td rowspan=1 colspan=1>89.6%</td><td rowspan=1 colspan=1>89.4%</td><td rowspan=1 colspan=1>0.2%</td></tr><tr><td rowspan=1 colspan=1>Soft Tissue Tumors</td><td rowspan=1 colspan=1>96.6%</td><td rowspan=1 colspan=1>93.1%</td><td rowspan=1 colspan=1>3.4%</td></tr><tr><td rowspan=1 colspan=1>Stomach</td><td rowspan=1 colspan=1>92.4%</td><td rowspan=1 colspan=1>93.6%</td><td rowspan=1 colspan=1>-1.2%</td></tr><tr><td rowspan=1 colspan=1>Overall</td><td rowspan=1 colspan=1>92.0%</td><td rowspan=1 colspan=1>92.6%</td><td rowspan=1 colspan=1>-0.6%</td></tr></table>

The difference in modality agreement, DR-MR, ranged from $- 2 . 9 \%$ for lung to $3 . 4 \%$ for soft tissue tumors. Three organ types, gallbladder, gynecological, and hernial/peritoneal had no differences (difference between reading modalities of $0 . 0 \%$ ). For all organ types, the overall agreement rate was $9 2 . 0 \%$ for DR and $9 2 . 6 \%$ for MR, with a difference in agreement (DRMR) of - $. 0 . 6 \%$ . The lowest agreement in both modalities was observed with bladder cases, with an agreement rate of $8 5 . 9 \%$ for DR and $8 7 . 8 \%$ for MR.

When considering the 1592 cases where all 4 Reading Pathologists at the site provided successfully adjudicated diagnoses for both DR and MR, there were a total of 9552 MR/MR comparisons and 9552 DR/DR comparisons between each possible pair of readers for agreement rate calculation. Overall, when considering all reader comparisons across all sites, the between-reader agreement rate was $9 1 . 4 \%$ b $9 5 \%$ CI: 90.8, 91.9) for MR, and $9 0 . 6 \%$ b $9 5 \%$ CI: 90.0, 91.1) for DR. The between-reader agreement rate ranged from $8 6 . 9 \%$ to $9 5 . 2 \%$ for MR, and $8 5 . 1 \%$ to $9 4 . 5 \%$ for DR.

# B. Precision Study

1. Analytical performance a. Reproducibility/Precision:

The objective of the reproducibility/precision study was to evaluate the between-site, between-day, between-reader, and within-reader precision of Roche Digital Pathology Dx. The study was designed to examine the full scope of device variability, with multiple Reading Pathologists (readers) independently identifying specific histological primary features in multiple Regions of Interest (ROIs, which is an equivalent term to the predicate’s usage of “Fields of View [FOVs]”) pre-selected on WSI scans generated by multiple VENTANA DP 200 scanners (at multiple external pathology laboratories) across multiple scanning days.

The precision of the device was evaluated based on the ability of 2 readers at each of 3 external pathology laboratories (study sites) to consistently detect 23 protocol-specified histopathologic primary feature types in VENTANA DP 200 WSI scans of hematoxylin and eosin (H&E)-stained archival slides containing sections of a variety of FFPE human tissue and organ types. The list of 23 primary feature types examined (shown in Table 1) was identical to those examined in the predicate device precision study, although the cases tested were unique to the Roche study. Scanning was performed at either $2 0 \mathrm { x }$ (for 12 primary feature types) or at $4 0 \mathrm { x }$ (for 11 primary feature types) as designated by the study protocol.

For each of the 23 feature types, 3 unique study cases, generally from different organ systems or tissue types (see Table 1 for distribution), were enrolled and included in the study analyses, for a total analysis cohort of 69 cases (slides). H&E-stained slides from 12 additional unique cases were included in the study as “wild card” slides to reduce recall bias but were excluded from the statistical analyses, as in the predicate studies. Each of the wild card slides also contained 3 ROIs selected by the Screening Pathologist, but the 3 ROIs for a given wild card slide did not have to contain the same type of primary feature. Since each slide enrolled in the study contained 3 ROIs, a total of 207 “study” ROIs (69 study cases x 3 ROIs/study case) were included in the analyses, and an additional 36 wild card ROIs (12 wild card cases x 3 ROIs/wild card case) were included in the study.

Table 5: Primary Histologic Study Features Used in the Precision Study   

<table><tr><td colspan="1" rowspan="1">Primary Feature(Scanning MagnificationLevel)</td><td colspan="3" rowspan="1">Organ Systems/Tissue Types of the 3 Enrolled Study Cases</td></tr><tr><td colspan="1" rowspan="1">Chondrocytes (20x)</td><td colspan="1" rowspan="1">Bone (left proximalhumerus)</td><td colspan="1" rowspan="1">Bone (right scapula)</td><td colspan="1" rowspan="1">Soft tissue (chest, xiphoid)</td></tr><tr><td colspan="1" rowspan="1">Fat cells (adipocytes) (20x)</td><td colspan="1" rowspan="1">Lymph node (anteriorprostatic</td><td colspan="1" rowspan="1">Lymph node (pelvis,right)</td><td colspan="1" rowspan="1">Omentum</td></tr><tr><td colspan="1" rowspan="1">Foreign body giant cells (20x)</td><td colspan="1" rowspan="1">Breast (lower outer)</td><td colspan="1" rowspan="1">Liver #1</td><td colspan="1" rowspan="1">Soft tissue (sixthintercostal muscle</td></tr><tr><td colspan="1" rowspan="1">Goblet cells (20x)</td><td colspan="1" rowspan="1">Colon (ascending)</td><td colspan="1" rowspan="1">Duodenum (secondportion)</td><td colspan="1" rowspan="1">Lung (left upper lobe)</td></tr><tr><td colspan="1" rowspan="1">Granulomas (20x)</td><td colspan="1" rowspan="1">Lung (left lower lobe)</td><td colspan="1" rowspan="1">Lymph node (inguinal)</td><td colspan="1" rowspan="1">Lymph node (rightaxillary)</td></tr><tr><td colspan="1" rowspan="1">Infiltrating or metastatic lobularcarcinoma (20x)</td><td colspan="1" rowspan="1">Breast (left)</td><td colspan="1" rowspan="1">Breast (right)</td><td colspan="1" rowspan="1">Chest wall (right)</td></tr><tr><td colspan="1" rowspan="1">Intraglandular necrosis (20x)</td><td colspan="1" rowspan="1">Breast (left)</td><td colspan="1" rowspan="1">Breast(right, lower outerquadrant)</td><td colspan="1" rowspan="1">Oral cavity(left buccal mucosa)</td></tr><tr><td colspan="1" rowspan="1">Osteoclasts (20x)</td><td colspan="1" rowspan="1">Bone (fibula, proximal,lesion, right)</td><td colspan="1" rowspan="1">Bone (left temporalbone)</td><td colspan="1" rowspan="1">Bone (tibia, left)</td></tr><tr><td colspan="1" rowspan="1">Osteocytes (20x)</td><td colspan="1" rowspan="1">Bone (frontal, right)</td><td colspan="1" rowspan="1">Bone (right tibia)</td><td colspan="1" rowspan="1">Pelvis(left, acetabular lesion)</td></tr><tr><td colspan="1" rowspan="1">Pleomorphic nucleus ofmalignant cell (20x)</td><td colspan="1" rowspan="1">Brain (right temporalmass)</td><td colspan="1" rowspan="1">Soft tissue (left thigh)</td><td colspan="1" rowspan="1">Soft tissue (right thigh)</td></tr><tr><td colspan="1" rowspan="1">Serrated intestinal epithelium(eg, sessile serrated polyp) (20x)</td><td colspan="1" rowspan="1">Colon (ascending, polyp)</td><td colspan="1" rowspan="1">Colon (ascending, polyp)</td><td colspan="1" rowspan="1">Colon (ascending, polyp)</td></tr><tr><td colspan="1" rowspan="1">Skeletal muscle fibers (20x)</td><td colspan="1" rowspan="1">Breast (left)</td><td colspan="1" rowspan="1">Left thigh</td><td colspan="1" rowspan="1">Thyroid gland</td></tr><tr><td colspan="1" rowspan="1">Asteroid bodies (40x)</td><td colspan="1" rowspan="1">Knee, right, synovium #3</td><td colspan="1" rowspan="1">Lung (upper lobe)</td><td colspan="1" rowspan="1">Lymph node</td></tr><tr><td colspan="1" rowspan="1">Clear cells (40x)</td><td colspan="1" rowspan="1">Aorta, inter aorta cavallymph node</td><td colspan="1" rowspan="1">Left kidney</td><td colspan="1" rowspan="1">Ovary and fallopian tube</td></tr><tr><td colspan="1" rowspan="1">Foreign bodies (eg, plantmaterial or foreign debris) (40x)</td><td colspan="1" rowspan="1">Aorta, ascending,pseudoaneurysm wall</td><td colspan="1" rowspan="1">Small intestine and colon</td><td colspan="1" rowspan="1">Soft tissue (abdomen)</td></tr><tr><td colspan="1" rowspan="1">Hemosiderin (pigment) (40x)</td><td colspan="1" rowspan="1">Breast (left chest wallnodule)</td><td colspan="1" rowspan="1">Breast (right)</td><td colspan="1" rowspan="1">Breast (right)</td></tr><tr><td colspan="1" rowspan="1">Megakaryocytes (40x)</td><td colspan="1" rowspan="1">Bone(distal sternum andright ribs)</td><td colspan="1" rowspan="1">Bone (rib, right)</td><td colspan="1" rowspan="1">Buttock (left, lesion)</td></tr><tr><td colspan="1" rowspan="1">Necrosis (40x)</td><td colspan="1" rowspan="1">Lung (right lower lobe)</td><td colspan="1" rowspan="1">Lung (right upper lobe)</td><td colspan="1" rowspan="1">Right great toe</td></tr><tr><td colspan="1" rowspan="1">Nerve cell bodies (eg, ganglioncells) (40x)</td><td colspan="1" rowspan="1">Colon (cecum, polyp x2)</td><td colspan="1" rowspan="1">Esophagus</td><td colspan="1" rowspan="1">Soft tissue(left paraspinal)</td></tr><tr><td colspan="1" rowspan="1">Nuclear grooves (40x)</td><td colspan="1" rowspan="1">Bone (left acetabulum)</td><td colspan="1" rowspan="1">Left fallopian tube andleft ovary</td><td colspan="1" rowspan="1">Thyroid (right)</td></tr><tr><td colspan="1" rowspan="1">Osteoid matrix (40x)</td><td colspan="1" rowspan="1">Bone (left acetabulum)</td><td colspan="1" rowspan="1">Bone (right tibia)</td><td colspan="1" rowspan="1">Bone (right ulna)</td></tr><tr><td colspan="1" rowspan="1">Psammoma bodies (40x)</td><td colspan="1" rowspan="1">Brain (posterior fossatumor)</td><td colspan="1" rowspan="1">Brain (right frontal tumor)</td><td colspan="1" rowspan="1">Thyroid (lobe, Ileft)</td></tr><tr><td colspan="1" rowspan="1">Reed-Sternberg cell (40x)</td><td colspan="1" rowspan="1">Lymph node (cervical rht,level IV)</td><td colspan="1" rowspan="1">Neck mass (right)</td><td colspan="1" rowspan="1">Thymus</td></tr></table>

The ROIs from the 3 scanning sessions at each site were independently evaluated by the 2 readers at that site in 3 different reading sessions (1 reading session per scanning day) with at least a 2-week washout period in between each reading session. In each reading session, each reader evaluated, in randomized fashion, all 207 study ROIs from each of 3 scanning sessions (across 3 scanning systems) at their site, plus the randomly interspersed, unique “wild card” ROIs to reduce recall bias between reading sessions.

Thus, all 6 readers evaluated 207 study ROIs (and 36 wild card ROIs) in each of 3 different reading sessions, and their study ROI assessments were used for the co-primary analyses of between-system/site, between-day/within-system, and between-reader precision. Each reader also participated in a fourth reading session in which they re-evaluated their site’s day 1 ROI images in a different random order; their 2 assessments for each day 1 ROI image were then compared to each other to determine within-reader precision as an additional analysis.

In each of their reading sessions, each reader accessed the designated ROI images from their site in uPath and evaluated them to identify any primary features that were present, using a checklist of the 23 protocol-specified primary features and their designated magnification levels as a reference. During their evaluations, readers were provided with the scanning magnification level and organ system/tissue type (conveyed as shown in Table 1) for the ROI image and were able to move about freely on the ROI image, varying the viewing magnification as desired, but they were blinded to case ID, patient clinical information and sign-out diagnoses, and all previous screening or study results. Each primary feature assessment for a study case ROI image was then compared to the reference primary feature for that case, and the agreement that the reference feature was present was evaluated between readers, between sites, and between scanning days. As with the predicate device’s precision study, if a reader identified a primary feature other than the reference feature as present in a given ROI image (in addition to or instead of the reference feature), that non-reference

identification had no effect on the study endpoints. Only the results from the study ROIs were used in the statistical analyses; those from wild card ROIs were excluded from the analyses. The precision of the system was to be considered acceptable if the lower bounds of the 2- sided $9 5 \%$ CIs for all co-primary endpoints (i.e., the overall percent agreement [OPA] point estimate for between-site/system, between-day/within-system, and between-reader agreement) were at least $8 5 \%$ . No acceptance criterion was defined for within-reader agreement.

# Results of the Precision Analyses

The results of the co-primary analyses of precision (between-site/system, betweenday/within-system, and between-reader OPA point estimates) are summarized below in Table 6. More details of these analyses are provided in the following sections, followed by a discussion of the within-reader analysis and results. For each of the co-primary analyses, the lower bounds of the $9 5 \%$ CI for the 3 OPA point estimate was $5 8 5 \%$ , demonstrating that Roche Digital Pathology Dx has acceptable precision. For these analyses, OPA was aggregated across the other sources of variation (eg, between-sites OPA was aggregated across readers and days).

Table 6: Overall Percent Agreement Rates for Co-Primary Endpoints   

<table><tr><td rowspan=1 colspan=1>Co-Primary Endpoint</td><td rowspan=1 colspan=1>OPA (n/N)*</td><td rowspan=1 colspan=1>95% CI**</td></tr><tr><td rowspan=1 colspan=1>Between-Site/System</td><td rowspan=1 colspan=1>89.3 (19510/21839)</td><td rowspan=1 colspan=1>(85.8, 92.4)</td></tr><tr><td rowspan=1 colspan=1>Between-Days/Within-System</td><td rowspan=1 colspan=1>90.3 (3302/3656)</td><td rowspan=1 colspan=1>(87.1, 93.2)</td></tr><tr><td rowspan=1 colspan=1>Between-Readers</td><td rowspan=1 colspan=1>90.1 (1650/1832)</td><td rowspan=1 colspan=1>(86.6, 93.0)</td></tr></table>

\*n $=$ number of pairwise comparisons for which the reference primary feature was identified in both assessments; $\Nu =$ total number of pairwise comparisons. \*\*Two-sided $9 5 \%$ confidence intervals were constructed using the percentile bootstrap method from 2000 replicates.

Table 7: Between-Site/Between-System Precision Study Results   

<table><tr><td rowspan=2 colspan=1>System</td><td rowspan=2 colspan=1>Number of PairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparison Pairs</td><td rowspan=1 colspan=2>Agreement Rate and 95% Cl</td></tr><tr><td rowspan=1 colspan=1>% Agreement</td><td rowspan=1 colspan=1>95% Cl</td></tr><tr><td rowspan=1 colspan=1>Site A vs. Site B</td><td rowspan=1 colspan=1>6277</td><td rowspan=1 colspan=1>7210</td><td rowspan=1 colspan=1>87.1</td><td rowspan=1 colspan=1>(83.2, 90.7)</td></tr><tr><td rowspan=1 colspan=1>Site A vs. Site C</td><td rowspan=1 colspan=1>6572</td><td rowspan=1 colspan=1>7284</td><td rowspan=1 colspan=1>90.2</td><td rowspan=1 colspan=1>(86.8, 93.3)</td></tr><tr><td rowspan=1 colspan=1>Site B vs. Site C</td><td rowspan=1 colspan=1>6661</td><td rowspan=1 colspan=1>7345</td><td rowspan=1 colspan=1>90.7</td><td rowspan=1 colspan=1>(87.2, 93.8)</td></tr><tr><td rowspan=1 colspan=1>Overall</td><td rowspan=1 colspan=1>19510</td><td rowspan=1 colspan=1>21839</td><td rowspan=1 colspan=1>89.3</td><td rowspan=1 colspan=1>(85.8, 92.4)</td></tr></table>

# Between-Day / Within-System Precision

Between-day (within-system) precision was analyzed by first performing all possible pairwise comparisons between days for each reader separately (ie, for each reader, their Day 1 results were compared to their Day 2 results, their Day 2 results were compared to their Day 3 results, and their Day 1 results were compared to their Day 3 results) and then pooling the 3 day-pair results together. These individual reader results were then aggregated across all readers at all sites to determine overall between-day/within-system precision.

Table 8: Between-Day / Within-System Precision Study Results   

<table><tr><td rowspan=2 colspan=1>Site, Reader</td><td rowspan=2 colspan=1>Number of Dayto Day PairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparison Pairs</td><td rowspan=1 colspan=2>Agreement Rate and 95% Cl</td></tr><tr><td rowspan=1 colspan=1>% Agreement</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Site A, Reader 1</td><td rowspan=1 colspan=1>495</td><td rowspan=1 colspan=1>592</td><td rowspan=1 colspan=1>83.6</td><td rowspan=1 colspan=1>(78.7, 88.2)</td></tr><tr><td rowspan=1 colspan=1>Site A, Reader 2</td><td rowspan=1 colspan=1>549</td><td rowspan=1 colspan=1>607</td><td rowspan=1 colspan=1>90.4</td><td rowspan=1 colspan=1>(86.0, 94.6)</td></tr><tr><td rowspan=1 colspan=1>Site B, Reader 1</td><td rowspan=1 colspan=1>540</td><td rowspan=1 colspan=1>613</td><td rowspan=1 colspan=1>88.1</td><td rowspan=1 colspan=1>(83.7, 92.3)</td></tr><tr><td rowspan=1 colspan=1>Site B, Reader 2</td><td rowspan=1 colspan=1>541</td><td rowspan=1 colspan=1>604</td><td rowspan=1 colspan=1>89.6</td><td rowspan=1 colspan=1>(84.9, 93.7)</td></tr><tr><td rowspan=1 colspan=1>Site C, Reader 1</td><td rowspan=1 colspan=1>607</td><td rowspan=1 colspan=1>621</td><td rowspan=1 colspan=1>97.7</td><td rowspan=1 colspan=1>(94.8, 100.0)</td></tr><tr><td rowspan=1 colspan=1>Site C, Reader 2</td><td rowspan=1 colspan=1>570</td><td rowspan=1 colspan=1>619</td><td rowspan=1 colspan=1>92.1</td><td rowspan=1 colspan=1>(88.4, 95.5)</td></tr><tr><td rowspan=1 colspan=1>Overall</td><td rowspan=1 colspan=1>3302</td><td rowspan=1 colspan=1>3656</td><td rowspan=1 colspan=1>90.3</td><td rowspan=1 colspan=1>(87.1, 93.2)</td></tr></table>

# Between-Reader Precision

In the between-reader precision analysis, the pairwise agreement between the 2 readers within a site (ie, between the 2 readers at Site A, between the 2 readers at Site B, and between the 2 readers at Site C) was analyzed separately for each site, and these pairwise results were then pooled across all sites.

Table 9: Between-Reader Precision Study Results   

<table><tr><td rowspan="2">Pathologist (Reader)</td><td rowspan="2">Number of Pairwise Agreements</td><td rowspan="2">Number of Comparison Pairs</td><td colspan="2">Agreement Rate and 95% Cl</td></tr><tr><td>% Agreement</td><td>95% CI</td></tr><tr><td>Reader A1 vs A2</td><td>528</td><td>603</td><td>87.6</td><td>(83.3, 91.4)</td></tr><tr><td>Reader B1 vs B2</td><td>536</td><td>609</td><td>88.0</td><td>(83.6, 92.2)</td></tr><tr><td>Reader C1 vs C2</td><td>586</td><td>620</td><td>94.5</td><td>(91.5, 97.3)</td></tr><tr><td>Overall</td><td>1650</td><td>1832</td><td>90.1</td><td>(86.6, 93.0)</td></tr></table>

# Within-Reader Precision

The within-reader precision analysis compared each reader’s first assessment of their site’s Day 1 ROI images (performed in their first reading session) with the same reader’s second assessment of the same ROI images (performed in their fourth reading session), with the images presented in a different random order in each session. Due to the minimum 2-week washout period between reading sessions 1, 2, 3, and 4, the assessments used in the withinreader precision analyses therefore were performed at least 6 weeks apart. Pairwise agreement between reads was assessed for each reader separately, and the results were aggregated across all readers at all sites to determine the overall OPA for within-reader precision. Within-reader precision did not have a predefined acceptance criterion.

Table 10: Within-Reader Precision Study Results   

<table><tr><td rowspan=2 colspan=1>Pathologist (Reader)</td><td rowspan=2 colspan=1>Number of PairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparison Pairs</td><td rowspan=1 colspan=2>Agreement Rate and 95% Cl</td></tr><tr><td rowspan=1 colspan=1>% Agreement</td><td rowspan=1 colspan=1>95% Cl</td></tr><tr><td rowspan=1 colspan=1>Site A, Reader 1</td><td rowspan=1 colspan=1>160</td><td rowspan=1 colspan=1>200</td><td rowspan=1 colspan=1>80.0</td><td rowspan=1 colspan=1>(73.4, 86.1)</td></tr><tr><td rowspan=1 colspan=1>Site A, Reader 2</td><td rowspan=1 colspan=1>183</td><td rowspan=1 colspan=1>203</td><td rowspan=1 colspan=1>90.1</td><td rowspan=1 colspan=1>(85.7, 94.5)</td></tr><tr><td rowspan=1 colspan=1>Site B, Reader 1</td><td rowspan=1 colspan=1>172</td><td rowspan=1 colspan=1>206</td><td rowspan=1 colspan=1>83.5</td><td rowspan=1 colspan=1>(78.0, 88.9)</td></tr><tr><td rowspan=1 colspan=1>Site B, Reader 2</td><td rowspan=1 colspan=1>175</td><td rowspan=1 colspan=1>201</td><td rowspan=1 colspan=1>87.1</td><td rowspan=1 colspan=1>(81.4, 92.0)</td></tr><tr><td rowspan=1 colspan=1>Site C, Reader 1</td><td rowspan=1 colspan=1>202</td><td rowspan=1 colspan=1>207</td><td rowspan=1 colspan=1>97.6</td><td rowspan=1 colspan=1>(94.7, 100.0)</td></tr><tr><td rowspan=1 colspan=1>Site C, Reader 2</td><td rowspan=1 colspan=1>186</td><td rowspan=1 colspan=1>206</td><td rowspan=1 colspan=1>90.3</td><td rowspan=1 colspan=1>(86.0, 94.2)</td></tr><tr><td rowspan=1 colspan=1>Overall</td><td rowspan=1 colspan=1>1078</td><td rowspan=1 colspan=1>1223</td><td rowspan=1 colspan=1>88.1</td><td rowspan=1 colspan=1>(84.8, 91.3)</td></tr></table>

# CONCLUSION

The submitted information in this premarket notification is complete and supports a substantial equivalence decision.