# 510(k) SUBSTANTIAL EQUIVALENCE DETERMINATION DECISION SUMMARY

I Background Information:

A 510(k) Number K232879 B Applicant

Ventana Medical Systems, Inc.

# C Proprietary and Established Names

Roche Digital Pathology Dx (VENTANA DP 200)

D Regulatory Information

<table><tr><td rowspan=1 colspan=1>ProductCode(s)</td><td rowspan=1 colspan=1>Classification</td><td rowspan=1 colspan=1>RegulationSection</td><td rowspan=1 colspan=1>Panel</td></tr><tr><td rowspan=1 colspan=1>PSY</td><td rowspan=1 colspan=1>Class II</td><td rowspan=1 colspan=1>21 CFR 864.3700</td><td rowspan=1 colspan=1>88-Pathology</td></tr></table>

II Submission/Device Overview:

A Purpose for Submission: New device   
B Type of Test: Digital pathology whole slide imaging

# III Intended Use/Indications for Use:

# A Intended Use(s):

Roche Digital Pathology Dx (VENTANA DP 200) is an automated digital slide creation, viewing and management system. Roche Digital Pathology Dx (VENTANA DP 200) is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of scanned pathology slides prepared from formalin-fixed paraffin-embedded (FFPE) tissue. Roche

Digital Pathology Dx (VENTANA DP 200) is not intended for use with frozen section, cytology, or non-FFPE hematopathology specimens. Roche Digital Pathology Dx (VENTANA DP 200) is for creation and viewing of digital images of scanned glass slides that would otherwise be appropriate for manual visualization by conventional light microscopy.

Roche Digital Pathology Dx (VENTANA DP 200) is composed of VENTANA DP 200 slide scanner, Roche uPath enterprise software, and ASUS PA248QV display. It is the responsibility of a qualified pathologist to employ appropriate procedures and safeguards to assure the validity of the interpretation of images obtained using Roche Digital Pathology Dx (VENTANA DP 200).

# B Indication(s) for Use:

Same as Intended Use.

# C Special Conditions for Use Statement(s):

Rx - For Prescription Use Only For In vitro diagnostic (IVD) use only

# IV Device/System Characteristics:

# A Device Description:

The Roche Digital Pathology Dx (VENTANA DP 200) is a Whole Slide Imaging (WSI) system which includes the following components.

 VENTANA DP 200 slide scanner  Roche uPath enterprise software Display (ASUS PA248QV)

The VENTANA DP 200 slide scanner is a bright-field digital pathology scanner that accommodates loading and scanning of up to 6 standard-sized (1 x 3 inch) glass slides. The scanner comprises a high-resolution $2 0 \mathrm { x }$ objective with the ability to scan at both magnification levels of $2 0 \mathrm { x }$ and $4 0 \mathrm { x }$ . The scanner features automatic detection of the tissue specimen on the slide, automated 1D and 2D barcode reading and selectable volume scanning. It also integrates color profiling to ensure that images produced from scanned slides are generated with a color-managed International Color Consortium (ICC) profile. After initial quality control of the slides, a batch of up to 6 slides is loaded into the slide tray of the scanner and scanning is initiated. For each slide, the scanner generates a macro image that includes the barcode label and a low-magnification image of tissue on the slide and locates the stained tissue within the slide scan area. Scanning is performed at high resolution $0 . 4 6 5 ~ { \mu \mathrm { m } } /$ pixel for $2 0 \mathrm { x }$ and $0 . 2 5 ~ \mu \mathrm { m }$ pixel for 40x). The resulting image files are compressed, saved in the BIF file format, and are transferred into either the uPath IMS (Image Management System) server or the uPath server by the iScan API (a part of the DP 200 Scan Application software).

The Roche uPath enterprise software (uPath) component of the Roche Digital Pathology system which contains the image viewer, is a web-based image management and workflow software application. The uPath software interface enables the user to review the digital image on the display screen and report results.

The ASUS PA248QV display allows the slide images to be viewed. The ASUS PA248QV features an IPS LCD color display with a display area of $5 1 8 . 4 \ \mathrm { m m } \times 3 2 4 . 0 \ \mathrm { m m }$ , a resolution of $1 , 9 2 0 \times$ 1,200 pixels and an aspect ratio of 16:10, illuminated by an edge LED backlight.

# Instrument Description Information:

1. Instrument Name: Roche Digital Pathology Dx (VENTANA DP 200)

2. Specimen Identification:

Glass slides and scanned images are identified based on the previously assigned specimen identifiers such as patient identifiers, barcodes, etc. Digital images of surgical pathology slides prepared from FFPE tissue.

3. Specimen Sampling and Handling:

Specimen sampling and handling are performed upstream and independent of the use of the subject device. Specimen sampling includes surgical pathology specimens such as biopsy or resection specimens which are processed using standard histology techniques. The FFPE tissue sections are stained using the Hematoxylin and Eosin (H&E) staining procedure. Then digital images are obtained from these glass slides using the VENTANA DP 200 scanner. Glass slides are identified by automatic reading of 1D and 2D barcode on slide label.

# 4. Calibration:

The VENTANA DP 200 scanner is calibrated and verified at the factory before shipment and confirmed by authorized Roche technicians as part of the installation process. Additionally, the scanner requires regular (monthly) diagnostic tests run automatically after user-initiation and has separate regular self-calibration activities upon each power-up and hourly during use. The scanner also provides automatic calibration and verification every time a slide is scanned by performing calibration during the scan. The display provided with Roche Digital Pathology Dx (VENTANA DP 200) has been calibrated at the factory; the user should not attempt to change the monitor settings as doing so may interfere with the monitor calibration. The uPath software application does not require calibration.

# 5. Quality Control:

Quality control (QC) activities are performed by the user per the laboratory standards and professional guidelines (e.g., staining, cover-slipping, barcode placement) prior to loading the slides into the VENTANA DP 200. After completing a scan, the lab technician checks image data and image quality as per the instructions for use. Before review, the pathologist ensures the quality of the WSI images before reviewing the image for diagnostic purposes.

# V Substantial Equivalence Information:

A Predicate Device Name(s): Aperio AT2 DX System B Predicate 510(k) Number(s): K190332 C Comparison with Predicate(s):

<table><tr><td colspan="1" rowspan="1">Device &amp;PredicateDevice(s):</td><td colspan="1" rowspan="1">K232879Roche Digital Pathology Dx(VENTANA DP 200)</td><td colspan="1" rowspan="1">K190332Aperio AT2 DX System</td></tr><tr><td colspan="3" rowspan="1">General Device Characteristics: Similarities</td></tr><tr><td colspan="1" rowspan="1">Intended Use</td><td colspan="1" rowspan="1">Roche Digital Pathology Dx (VENTANADP 200) is an automated digital slidecreation, viewing and managementsystem. Roche Digital Pathology Dx(VENTANA DP 200) is intended for invitro diagnostic use as an aid to thepathologist to review and interpret digitalimages of scanned pathology slidesprepared from formalin-fixed paraffin-embedded (FFPE) tissue. Roche DigitalPathology Dx (VENTANA DP 200) is notintended for use with frozen section,cytology, or non-FFPE hematopathologyspecimens. Roche Digital Pathology Dx(VENTANA DP 200) is for creation andviewing of digital images of scanned glassslides that would otherwise be appropriatefor manual visualization by conventionallight microscopy.Roche Digital Pathology Dx (VENTANADP 200) is composed of VENTANA DP200 slide scanner, Roche uPath enterprisesoftware, and ASUS PA248QV display. It obtained using the Aperio AT2 DX System.is the responsibility of a qualifiedpathologist to employ appropriateprocedures and safeguards to assure thevalidity of the interpretation of imagesobtained using Roche Digital PathologyDx (VENTANA DP 200).</td><td colspan="1" rowspan="1">The Aperio AT2 DX System is an automateddigital slide creation and viewing system.The Aperio AT2 DX System is intended forin vitro diagnostic use as an aid to thepathologist to review and interpret digitalimages of surgical pathology slides preparedfrom formalin-fixed paraffin embedded(FFPE) tissue. The Aperio AT2 DX Systemis not intended for use with frozen section,cytology, or non-FFPE hematopathologyspecimens.The Aperio AT2 DX System is composed ofthe AperioAT2 DX scanner, the ImageScopeDX review application and Display. TheAperio AT2 DX System is for creation andviewing of digital images of scanned glassslides that would otherwise be appropriatefor manual visualization by conventionallight microscopy. It is the responsibility of aqualified pathologist to employ appropriateprocedures and safeguards to assure thevalidity of the interpretation of imagessoftware, and ASUS PA248QV display. It obtained using the Aperio AT2 DX System.</td></tr><tr><td colspan="1" rowspan="1">Principle ofOperation</td><td colspan="1" rowspan="1">After conducting Quality Control (QC) onthe glass slides per laboratory standards(e.g., staining, coverslipping, barcodeplacement, etc.), the technician loads theslides into the VENTANA DP 200 slidescanner. The scanner scans the slides andgenerates a whole slide image for eachslide. The technician performs QC onscanned WSI images by checking imagedata and image quality. When QC fails,the slide will be re-scanned. The acquiredWSI images are stored in an end userprovided image storage attached to thelocal network. During review, thepathologist opens WSI images from theimage storage in Roche uPath enterprisesoftware, performs further QC to ensurelimage quality, and reads the WSI imagesof the slides to make a diagnosis.</td><td colspan="1" rowspan="1">Same</td></tr><tr><td colspan="1" rowspan="1">DeviceComponents</td><td colspan="1" rowspan="1">WSI scanner (VENTANA DP 200 slidescanner), Image Management System(Roche uPath enterprise software), andcolor monitor display</td><td colspan="1" rowspan="1">WSI scanner (Aperio AT2 DX scanner),Image Management System (ImageScope DXapplication) and color monitor display</td></tr><tr><td colspan="1" rowspan="1">ScanningMagnification</td><td colspan="1" rowspan="1">40x 20x</td><td colspan="1" rowspan="1">Same</td></tr><tr><td colspan="3" rowspan="1">General Device Characteristic: Differences</td></tr><tr><td colspan="1" rowspan="1">Whole SlideImagingScanner/slidecapacity</td><td colspan="1" rowspan="1">VENTANA DP 200/ 6 slides</td><td colspan="1" rowspan="1">Aperio AT2 DX/ 400 slides</td></tr><tr><td colspan="1" rowspan="1">Scan OutputImage Format</td><td colspan="1" rowspan="1">BIF</td><td colspan="1" rowspan="1">SVS</td></tr><tr><td colspan="1" rowspan="1">Reviewsoftware</td><td colspan="1" rowspan="1">Roche uPath</td><td colspan="1" rowspan="1">ImageScope DX</td></tr><tr><td colspan="1" rowspan="1">CompatibleDisplayMonitor)</td><td colspan="1" rowspan="1">ASUS PA248QV</td><td colspan="1" rowspan="1">Dell MR2416</td></tr></table>

# VI Standards/Guidance Documents Referenced:

1. Technical Performance Assessment of Digital Pathology Whole Slide Imaging Devices. Guidance for Industry and Food and Drug Administration Staff April 20, 2016.   
2. Applying Human Factors and Usability Engineering to Medical Devices: Guidance for Industry and Food and Drug Administration Staff. February 3, 2016.   
3. Guidance for the Content of Premarket Submissions for Software Contained in Medical Devices. Guidance for Industry and Food and Drug Administration Staff, May 2005.   
4. IEC/EN 61010-1:2010/AMD1: 2016, Safety requirements for electrical equipment for measurement, control, and laboratory use – Part 1: General requirements.   
5. IEC/EN 61010-2-101: 2018, Safety requirements for electrical equipment for measurement, control, and laboratory use – Part 2-101: Particular requirements for in vitro diagnostic (IVD) medical equipment.   
6. Electromagnetic Compatibility (EMC) of Medical Devices. Guidance for Industry and Food and Drug Administration Staff (June 6, 2022).

# VII Performance Characteristics (if/when applicable):

# A. Analytical Performance:

# 1. Precision/Reproducibility:

The objective of this study was to evaluate the repeatability (within- and between- system) and reproducibility (between-site) of the Roche Digital Pathology Dx (Ventana DP 200 scanner) device.

The precision of the device was evaluated based on the review and identification of specific histopathologic “features” that are observed in FFPE H&E stained slides by 2 pathologists (readers) at each of 3 external pathology laboratories (study sites) across multiple scanning days. Twenty-three (23) primary features were selected for inclusion into the studies. The selected primary features were evaluated at their relevant magnifications -12 primary features evaluated at $2 0 \mathrm { x }$ magnification level and 11 primary features evaluated at $4 0 \mathrm { x }$ magnification level. The reading pathologists independently identified specific histological primary features in multiple Regions of Interest (ROIs,) pre-selected on WSI scans generated by the VENTANA DP 200 scanner at each of 3 study sites.

For each of the 23 feature types, 3 unique study cases, generally from different organ systems or tissue types (see Table 1 below), were enrolled and included in the study analyses, for a total analysis cohort of 69 cases (slides). H&E-stained slides from 12 additional unique cases were included in the study as “wild card” slides to reduce recall bias but were excluded from the statistical analyses. Each of the wild card slides also contained 3 ROIs selected by the Screening Pathologist, but the 3 ROIs for a given wild card slide did not have to contain the same type of primary feature. Since each slide enrolled in the study contained 3 ROIs, a total of 207 “study” ROIs (69 study cases x 3 ROIs/study case) were included in the analyses, and an additional 36 wild card ROIs (12 wild card cases x 3 ROIs/wild card case) were included in the study.

Table 1. Primary Histologic Study Features in Precision Study   

<table><tr><td colspan="1" rowspan="1">Feature</td><td colspan="1" rowspan="1">Organ #1</td><td colspan="1" rowspan="1">Organ #2</td><td colspan="1" rowspan="1">Organ #3</td></tr><tr><td colspan="4" rowspan="1">20x Magnification</td></tr><tr><td colspan="1" rowspan="1">Chondrocytes</td><td colspan="1" rowspan="1">Bone (left proximalhumerus)</td><td colspan="1" rowspan="1">Bone (right scapula)</td><td colspan="1" rowspan="1">Soft tissue (chest,xiphoid)</td></tr><tr><td colspan="1" rowspan="1">Fat cells(adipocytes)</td><td colspan="1" rowspan="1">Lymph node (anteriorprostatic</td><td colspan="1" rowspan="1">Lymph node (pelvis,right)</td><td colspan="1" rowspan="1">Omentum</td></tr><tr><td colspan="1" rowspan="1">Foreign body giantcells</td><td colspan="1" rowspan="1">Breast, lower outer</td><td colspan="1" rowspan="1">Liver #1</td><td colspan="1" rowspan="1">Soft tissue (sixthintercostal muscle</td></tr><tr><td colspan="1" rowspan="1">Goblet cells</td><td colspan="1" rowspan="1">Colon (ascending)</td><td colspan="1" rowspan="1">Duodenum (secondportion)</td><td colspan="1" rowspan="1">Lung (left upper lobe)</td></tr><tr><td colspan="1" rowspan="1">Granulomas</td><td colspan="1" rowspan="1">Lung (left lower lobe)</td><td colspan="1" rowspan="1">Lymph node (inguinal)</td><td colspan="1" rowspan="1">Lymph node (rightaxillary)</td></tr><tr><td colspan="1" rowspan="1">Infiltrating ormetastatic lobularcarcinoma</td><td colspan="1" rowspan="1">Breast (left)</td><td colspan="1" rowspan="1">Breast (right)</td><td colspan="1" rowspan="1">Chest wall (right)</td></tr><tr><td colspan="1" rowspan="1">Intraglandularnecrosis</td><td colspan="1" rowspan="1">Breast (left)</td><td colspan="1" rowspan="1">Breast (right, lowerouter quadrant)</td><td colspan="1" rowspan="1">Oral cavity (left buccalmucosa)</td></tr><tr><td colspan="1" rowspan="1">Osteoclasts</td><td colspan="1" rowspan="1">Bone (fibula,proximal, lesion, right)</td><td colspan="1" rowspan="1">Bone (left temporalbone)</td><td colspan="1" rowspan="1">Bone (tibia, left)</td></tr><tr><td colspan="1" rowspan="1">Osteocytes</td><td colspan="1" rowspan="1">Bone (frontal, right)</td><td colspan="1" rowspan="1">Bone (right tibia)</td><td colspan="1" rowspan="1">Pelvis (left, acetabularlesion)</td></tr><tr><td colspan="1" rowspan="1">Pleomorphic nucleusof malignant cell</td><td colspan="1" rowspan="1">Brain (right temporalmass</td><td colspan="1" rowspan="1">Soft tissue (left thigh)</td><td colspan="1" rowspan="1">Soft tissue (right thigh)</td></tr><tr><td colspan="1" rowspan="1">Serrated intestinalepithelium (e.g.,sessile serratedpolyp)</td><td colspan="1" rowspan="1">Colon (ascending,polyp)</td><td colspan="1" rowspan="1">Colon (ascending,polyp)</td><td colspan="1" rowspan="1">Colon (ascending,polyp)</td></tr><tr><td colspan="1" rowspan="1">Skeletal musclefibers</td><td colspan="1" rowspan="1">Breast (left)</td><td colspan="1" rowspan="1">Left thigh</td><td colspan="1" rowspan="1">Thyroid gland</td></tr><tr><td colspan="4" rowspan="1">40x Magnification</td></tr><tr><td colspan="1" rowspan="1">Asteroid bodies</td><td colspan="1" rowspan="1">Knee, right, synovium#3</td><td colspan="1" rowspan="1">Lung (upper lobe)</td><td colspan="1" rowspan="1">Lymph node</td></tr><tr><td colspan="1" rowspan="1">Clear cells</td><td colspan="1" rowspan="1">Aorta, inter aorta cavallymph node</td><td colspan="1" rowspan="1">Left kidney</td><td colspan="1" rowspan="1">Ovary and fallopiantube</td></tr><tr><td colspan="1" rowspan="1">Foreign bodies (e.g.,plant material orforeign debris)</td><td colspan="1" rowspan="1">Aorta, ascending,pseudoaneurysm wall</td><td colspan="1" rowspan="1">Small intestine andcolon</td><td colspan="1" rowspan="1">Soft tissue (abdomen)</td></tr><tr><td colspan="1" rowspan="1">Hemosiderin(pigment)</td><td colspan="1" rowspan="1">Breast (left chest wallnodule)</td><td colspan="1" rowspan="1">Breast (right)</td><td colspan="1" rowspan="1">Breast (right)</td></tr><tr><td colspan="1" rowspan="1">Megakaryocytes</td><td colspan="1" rowspan="1">Bone (distal sternumand right ribs)</td><td colspan="1" rowspan="1">Bone (rib, right)</td><td colspan="1" rowspan="1">Buttock (left, lesion)</td></tr><tr><td colspan="1" rowspan="1">Necrosis</td><td colspan="1" rowspan="1">Lung (right lowerlobe)</td><td colspan="1" rowspan="1">Lung (right upper lobe)</td><td colspan="1" rowspan="1">Right great toe</td></tr><tr><td colspan="1" rowspan="1">Nerve cell bodies(e.g., ganglion cells)</td><td colspan="1" rowspan="1">Colon (cecum, polypx2</td><td colspan="1" rowspan="1">Esophagus</td><td colspan="1" rowspan="1">Soft tissue (leftparaspinal)</td></tr><tr><td colspan="1" rowspan="1">Nuclear grooves</td><td colspan="1" rowspan="1">Bone (left acetabulum)</td><td colspan="1" rowspan="1">Left fallopian tube andleft ovary</td><td colspan="1" rowspan="1">Thyroid (right)</td></tr><tr><td colspan="1" rowspan="1">Osteoid matrix</td><td colspan="1" rowspan="1">Bone (left acetabulum)</td><td colspan="1" rowspan="1">Bone (right tibia)</td><td colspan="1" rowspan="1">Bone (right ulna)</td></tr><tr><td colspan="1" rowspan="1">Psammoma bodies</td><td colspan="1" rowspan="1">Brain (posterior fossatumor)</td><td colspan="1" rowspan="1">Brain (right frontaltumor)</td><td colspan="1" rowspan="1">Thyroid (lobe, left)</td></tr><tr><td colspan="1" rowspan="1">Reed-Sternberg cell</td><td colspan="1" rowspan="1">Lymph node (cervicalright, level IV)</td><td colspan="1" rowspan="1">Neck mass (right)</td><td colspan="1" rowspan="1">Thymus</td></tr></table>

In each of their reading sessions, each reader accessed the designated ROI images from their site in uPath and evaluated them to identify any primary features that were present, using a checklist of the 23 protocol-specified primary features. During their evaluations, readers were provided with the scanning magnification level and organ system/tissue type for the ROI image and were able to move about freely on the ROI image, varying the viewing magnification as desired, however, they were blinded to case ID, patient clinical information and sign-out diagnoses and all previous screening or study results. Each primary feature assessment for a study case ROI image was then compared to the reference primary feature for that case. The reference feature with agreement was evaluated between readers, between sites, and between scanning days. If a reader identified a primary feature other than the reference feature as present in a given ROI image (in addition to or instead of the reference feature), that non-reference identification had no effect on the study endpoints. Only the results from the study ROIs were used in the statistical analyses; those from wild card ROIs were excluded from the analyses. The precision of the system was to be considered acceptable if the lower bounds of the 2-sided $9 5 \%$ confidence intervals (CIs) for all co-primary endpoints (i.e., the overall percent agreement (OPA) point estimate for between system/ between site, between day/within-system, and between reader (pathologist)/ within reader) were at least $8 5 \%$ .

The precision of the Roche Digital Pathology Dx was assessed in 3 sub-studies:   
• Between system (scanner)/Between Site precision using 3 independent systems.   
• Within system (scanner)/Between Day precision using 3 independent systems at 3 different sites.   
• Between reader (pathologist)/ Within reader precision.

The pairwise agreement of reference feature status between sites was analyzed for each site pair separately and then for all pairwise comparisons combined. For the analysis of OPA between sites, the 2 readers at each site and the 3 scanning days were considered. The comparison included all possible permutations between the 6 observations (2 readers $\times 3$ days) per ROI within a site, for a total of 36 $( 6 \times 6 )$ possible pairwise permutations between 2 sites per ROI. Agreements between systems at Site A versus Site B, systems at Site A versus Site C, and systems at Site B versus Site C were analyzed, then aggregated across readers and days. The overall between-site/system precision is based on the pooled data from all site-to-site comparisons. OPA for the analysis pooled across all site pairs was $8 9 . 3 \%$ $9 5 \%$ CI: 85.8, 92.4), satisfying the acceptance criterion. Study results are presented in the Table below.

Table 2. Between System/Between Site Agreement Rate   

<table><tr><td rowspan=2 colspan=1>System</td><td rowspan=2 colspan=1>Number ofPairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparisonPairs</td><td rowspan=1 colspan=2>Agreement Rate and 95% CI</td></tr><tr><td rowspan=1 colspan=1>% Agreement</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Site A vs. Site B</td><td rowspan=1 colspan=1>6277</td><td rowspan=1 colspan=1>7210</td><td rowspan=1 colspan=1>87.1</td><td rowspan=1 colspan=1>(83.2, 90.7)</td></tr><tr><td rowspan=1 colspan=1>Site A vs. Site C</td><td rowspan=1 colspan=1>6572</td><td rowspan=1 colspan=1>7284</td><td rowspan=1 colspan=1>90.2</td><td rowspan=1 colspan=1>(86.8, 93.3)</td></tr><tr><td rowspan=1 colspan=1>Site B vs. Site C</td><td rowspan=1 colspan=1>6661</td><td rowspan=1 colspan=1>7345</td><td rowspan=1 colspan=1>90.7</td><td rowspan=1 colspan=1>(87.2, 93.8)</td></tr><tr><td rowspan=1 colspan=1>Overall</td><td rowspan=1 colspan=1>19510</td><td rowspan=1 colspan=1>21839</td><td rowspan=1 colspan=1>89.3</td><td rowspan=1 colspan=1>(85.8, 92.4)</td></tr></table>

# Within System/Between Day Precision

This study evaluated the agreement between days for each scanner. Within system/Between Day precision was analyzed by first performing all possible pairwise comparisons between days for each reader separately (i.e., for each reader, their Day 1 results were compared to their Day 2 results, their Day 2 results were compared to their Day 3 results, and their Day 1 results were compared to their Day 3 results) and then pooling the 3 day-pair results together. These individual reader results were then aggregated across all readers at all sites to determine overall between-day/within-system precision. OPA for the analysis pooled across all site pairs was $9 0 . 3 \%$ ( $9 5 \%$ CI: 87.1, 93.2), satisfying the acceptance criterion for this endpoint ( $9 5 \%$ CI lower bound $\geq 8 5 \%$ ). Study results are presented in the Table below.

Table 3. Within System/Between Day Agreement Rates   

<table><tr><td colspan="1" rowspan="2">Site, Reader</td><td colspan="1" rowspan="2">Number of Day toDay PairwiseAgreements</td><td colspan="1" rowspan="2">Number ofComparison Pairs</td><td colspan="2" rowspan="1">Agreement Rate and 95% CI</td></tr><tr><td colspan="1" rowspan="1">% Agreement</td><td colspan="1" rowspan="1">95% CI</td></tr><tr><td colspan="1" rowspan="1">Site A, Reader 1</td><td colspan="1" rowspan="1">495</td><td colspan="1" rowspan="1">592</td><td colspan="1" rowspan="1">83.6</td><td colspan="1" rowspan="1">(78.7, 88.2)</td></tr><tr><td colspan="1" rowspan="1">Site A, Reader 2</td><td colspan="1" rowspan="1">549</td><td colspan="1" rowspan="1">607</td><td colspan="1" rowspan="1">90.4</td><td colspan="1" rowspan="1">(86.0, 94.6)</td></tr><tr><td colspan="1" rowspan="1">Site B, Reader 1</td><td colspan="1" rowspan="1">540</td><td colspan="1" rowspan="1">613</td><td colspan="1" rowspan="1">88.1</td><td colspan="1" rowspan="1">(83.7, 92.3)</td></tr><tr><td colspan="1" rowspan="1">Site B, Reader 2</td><td colspan="1" rowspan="1">541</td><td colspan="1" rowspan="1">604</td><td colspan="1" rowspan="1">89.6</td><td colspan="1" rowspan="1">(84.9, 93.7)</td></tr><tr><td colspan="1" rowspan="1">Site C, Reader 1</td><td colspan="1" rowspan="1">607</td><td colspan="1" rowspan="1">621</td><td colspan="1" rowspan="1">97.7</td><td colspan="1" rowspan="1">(94.8, 100.0)</td></tr><tr><td colspan="1" rowspan="1">Site C, Reader 2</td><td colspan="1" rowspan="1">570</td><td colspan="1" rowspan="1">619</td><td colspan="1" rowspan="1">92.1</td><td colspan="1" rowspan="1">(88.4, 95.5)</td></tr><tr><td colspan="1" rowspan="1">Overall</td><td colspan="1" rowspan="1">3302</td><td colspan="1" rowspan="1">3656</td><td colspan="1" rowspan="1">90.3</td><td colspan="1" rowspan="1">(87.1, 93.2)</td></tr></table>

# Between Reader Precision

In the between-reader precision analysis, the pairwise agreement between the 2 readers within a site (i.e., between the 2 readers at Site A, between the 2 readers at Site B and between the 2 readers at Site C) was analyzed separately for each site, and these pairwise results were then pooled across all sites. OPA for the analysis pooled across all sites was $9 0 . 1 \%$ ( $9 5 \%$ CI: 86.6, 93.0), satisfying the acceptance criterion for this endpoint ( $9 5 \%$ CI lower bound $\geq 8 5 \%$ ). Study results are presented in the Table below.

Table 4. Between Reader Agreement Rates   

<table><tr><td rowspan=2 colspan=1>Reader</td><td rowspan=2 colspan=1>Number ofPairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparisonPairs</td><td rowspan=1 colspan=2>Agreement Rate and 95% CI</td></tr><tr><td rowspan=1 colspan=1>% Agreement</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Reader A1 vs A2</td><td rowspan=1 colspan=1>528</td><td rowspan=1 colspan=1>603</td><td rowspan=1 colspan=1>87.6</td><td rowspan=1 colspan=1>(83.3, 91.4)</td></tr><tr><td rowspan=1 colspan=1>Reader B1 vs B2</td><td rowspan=1 colspan=1>536</td><td rowspan=1 colspan=1>609</td><td rowspan=1 colspan=1>88.0</td><td rowspan=1 colspan=1>(83.6, 92.2)</td></tr><tr><td rowspan=1 colspan=1>Reader C1 vs C2</td><td rowspan=1 colspan=1>586</td><td rowspan=1 colspan=1>620</td><td rowspan=1 colspan=1>94.5</td><td rowspan=1 colspan=1>(91.5, 97.3)</td></tr><tr><td rowspan=1 colspan=1>Overall</td><td rowspan=1 colspan=1>1650</td><td rowspan=1 colspan=1>1832</td><td rowspan=1 colspan=1>90.1</td><td rowspan=1 colspan=1>(86.6, 93.0)</td></tr></table>

# Within Reader Precision

The within-reader precision analysis compared each reader’s first assessment of their site’s Day 1 ROI images (performed in their first reading session) with the same reader’s second assessment of the same ROI images (performed in their fourth reading session), with the images presented in a different random order in each session. Due to the minimum 2-week washout period between reading sessions 1, 2, 3, and 4, the assessments used in the within-reader precision analyses therefore were performed at least 6 weeks apart. Pairwise agreement between reads was assessed for each reader separately, and the results were aggregated across all readers at all sites to determine the overall OPA for within-reader precision. Study results are presented in the Table below.

Table 5. Within Reader Agreement Rates   

<table><tr><td colspan="1" rowspan="2">Reader</td><td colspan="1" rowspan="2">Number ofPairwiseAgreements</td><td colspan="1" rowspan="2">Number ofComparisonPairs</td><td colspan="2" rowspan="1">Agreement Rate and 95% CI</td></tr><tr><td colspan="1" rowspan="1">% Agreement</td><td colspan="1" rowspan="1">95% CI</td></tr><tr><td colspan="1" rowspan="1">Site A, Reader 1</td><td colspan="1" rowspan="1">160</td><td colspan="1" rowspan="1">200</td><td colspan="1" rowspan="1">80.0</td><td colspan="1" rowspan="1">(73.4, 86.1)</td></tr><tr><td colspan="1" rowspan="1">Site A, Reader 2</td><td colspan="1" rowspan="1">183</td><td colspan="1" rowspan="1">203</td><td colspan="1" rowspan="1">90.1</td><td colspan="1" rowspan="1">(85.7, 94.5)</td></tr><tr><td colspan="1" rowspan="1">Site B, Reader 1</td><td colspan="1" rowspan="1">172</td><td colspan="1" rowspan="1">206</td><td colspan="1" rowspan="1">83.5</td><td colspan="1" rowspan="1">(78.0, 88.9)</td></tr><tr><td colspan="1" rowspan="1">Site B, Reader 2</td><td colspan="1" rowspan="1">175</td><td colspan="1" rowspan="1">201</td><td colspan="1" rowspan="1">87.1</td><td colspan="1" rowspan="1">(81.4, 92.0)</td></tr><tr><td colspan="1" rowspan="1">Site C, Reader 1</td><td colspan="1" rowspan="1">202</td><td colspan="1" rowspan="1">207</td><td colspan="1" rowspan="1">97.6</td><td colspan="1" rowspan="1">(94.7, 100.0)</td></tr><tr><td colspan="1" rowspan="1">Site C, Reader 2</td><td colspan="1" rowspan="1">186</td><td colspan="1" rowspan="1">206</td><td colspan="1" rowspan="1">90.3</td><td colspan="1" rowspan="1">(86.0, 94.2)</td></tr><tr><td colspan="1" rowspan="1">Overall</td><td colspan="1" rowspan="1">1078</td><td colspan="1" rowspan="1">1223</td><td colspan="1" rowspan="1">88.1</td><td colspan="1" rowspan="1">(84.8, 91.3)</td></tr></table>

2. Linearity:

Not applicable

3. Analytical Specificity/Interference: Not applicable

4. Accuracy (Instrument): Not applicable

5. Carry-Over: Not applicable

# B. Technical Studies:

Multiple studies were conducted to evaluate the performance of the Roche Digital Pathology Dx (Ventana DP200 scanner) as recommended in FDA guidance titled “Technical Performance Assessment of Digital Pathology Whole Slide Imaging Devices”.

a. Slide Feeder

Information was provided on the configuration of the slide feed mechanism, including a physical description of the slide, the number of slides in queue (carrier), and the class of automation. Information was provided on the user interaction with the slide feeder, including hardware, software, feedback mechanisms, and Failure Mode and Effects Analysis (FMEA).

a. Light source

Descriptive information associated with the lamp and the condenser was provided. Testing information was provided to verify the spectral distribution of the light source as part of the color reproduction capability of the VENTANA DP 200 scanner.

$b$ . Imaging optics

An optical schematic with all optical elements identified from slide (object plane) to digital image sensor (image plane) was provided. Descriptive information regarding the microscope objective, the auxiliary lenses, and the magnification of imaging optics was provided. Testing information regarding the relative irradiance, optical distortions, and lateral chromatic aberrations was provided.

c. Mechanical scanner movement

Information and specifications on the configuration of the stage, method of movement, control of movement of the stage, and FMEA was provided. Test data to verify the repeatability of the stage movement mechanism staying within limit during operation was provided.

# d. Digital imaging sensor

Information and specifications on the sensor type, pixel information, responsivity specifications, noise specifications, readout rate, and digital output format was provided. Test data to determine the correct functioning of the digital image sensor that converts optical signals of the slide to digital signals which consist of a set of numerical values corresponding to the brightness and color at each point in the optical image was provided.

e. Image processing software

Information and specifications on exposure control, white balance, color correction, subsampling, pixel-offset correction, pixel-gain or flat-field correction, and pixel-defect correction were provided.

$f .$ Image composition

Information and specifications on the scanning method, the scanning speed, and the number of planes at the Z-axis to be digitized were provided. Test data to analyze the image composition performance was provided.

# g. Image files format

Information and specifications on the compression method, compression ratio, file format, and file organization were provided.

h. Image review manipulation software

Information and specifications on continuous panning and pre-fetching, continuous zooming, discrete Z-axis displacement, the ability to compare multiple slides simultaneously on multiple windows, image enhancement and sharpening functions, color manipulation, annotation tools, and digital bookmarks were provided.

# i. Computer environment

Information and specifications on the computer hardware, operating system, graphics card, graphics card driver, color management settings, color profile, and display interface were provided.

# j. Display

Information and specifications on the technological characteristics of the display such as pixel density, aspect ratio, display viewing area, display surface, backlight type, panel type, viewing angle, pixel pitch, resolution, color space, max brightness, contrast ratio, response time, refresh rate (Max), color accuracy, color adjustment, gamma adjustment, adjustments, display interface, and certificate were provided. Test data to verify the performance of the display for user controls, spatial resolution, pixel defects (count and map), artifacts, temporal response, maximum and minimum luminance (achievable and recommended), grayscale, luminance uniformity, bidirectional reflection distribution function, gray tracking, color scale, and color gamut volume was provided.

k. Color reproducibility Test data to evaluate the color reproducibility of the system was provided.

l. Spatial resolution

Test data to evaluate the composite optical performance of all components in the image acquisition phase was provided.

m. Focusing test Test data to evaluate the technical focus quality of the system was provided.

n. Whole slide tissue coverage Test data to demonstrate that the entire tissue specimen on the glass slide is detected by the tissue detection algorithms and that all the tissue specimens are included in the digital image file was provided.

o. Stitching error Test data to evaluate the stitching errors and artifacts in the reconstructed image was provided.

p. Turnaround time Requirements to specify the turnaround time of the system was provided.

# C. Clinical Studies

A retrospective multi-center study was conducted to demonstrate that viewing, reviewing, and diagnosing digital images of surgical pathology FFPE tissue slides using the Roche Digital Pathology Dx (VENTANA DP 200) system is non-inferior to using traditional optical light microscopy. The primary endpoint was the difference in agreement rates between diagnoses rendered using Roche’s digital WSI review modality (digital read [DR]) and the manual microscopy slide review modality (manual read [MR]) when each was compared to the reference diagnosis, which is based on the original sign-out pathologic diagnosis rendered at the study sites using an optical (light) microscope. The study consisted of reviewing archived, de-identified and previously “signed-out” slides representing main organ systems within surgical pathology. Cases included retrospective H&E stained FFPE tissue, special stains and/or immunohistochemical stains (IHC) from the pathology practice, but did not include frozen sections, or cytological and hematological cases.

Four sites were used in the study. Two Screening Pathologists at each study site pre-screened cases from that site for possible inclusion in the study by reviewing their clinical database of archived specimens. Each site selected cases sequentially (chronologically or reverse chronologically) with a minimum of 1 year between the date of sign-out diagnosis and beginning of the study. The first Screening Pathologist reviewed all available H&E and ancillary-stains slides for each case using manual microscopy to determine whether the case met the study inclusion/exclusion criteria and confirmed the diagnosis related to that particular case by microscopically evaluating the H&E and ancillary stained slides along with the relevant clinical information as extracted from the sign-out report. For biopsy cases, the Screening Pathologist selected a representative H&E slide(s) (and IHC and special stain slides, if available), which were critical for a pathologist to reproduce the primary (reference) diagnosis. For non-biopsy cases, in addition to the representative H&E slide(s) (IHC and special stain slides, if available), slides from surgical specimen margins that were reported in the primary diagnosis were included. For malignant cases, slide(s) that provided the grading and positive and/or negative lymph node status that were reported in the primary diagnosis were also included. For a multi-part case, such as simultaneously obtained tissue biopsies from different areas of the organ, the first sequential case slide that matches a diagnostic category applicable to the pre-specified list of diagnoses was included in the study. Once the case slides were reviewed and selected by the first Screening Pathologist, the sign-out diagnosis report data captured on the screening case report forms (CRFs) was verified by a second Screening Pathologist to confirm the diagnostic accuracy of the case and whether the case met the study inclusion/exclusion criteria.

A total of 2047 cases (a total of 3259 slides) with approximately 500 per site consisting of multiple organ and tissue types were enrolled. At each site, all four Reading Pathologists read all the cases enrolled and scanned at that site using both MR and DR modalities in an alternating fashion and randomized order and with a washout period of at least 30 days between the MR and DR diagnoses. The 16 Reading Pathologists were provided with all representative slide(s) for each case at the same time, mimicking a practice setting.

Study inclusion/exclusion criteria are as follows:

# Inclusion Criteria:

Study slides should match one of the 20 pre-specified organ/tissue type categories listed in the study protocol and had to have a recorded sign-out diagnosis applicable to one of the pre-specified diagnoses listed in the study protocol.   
Surgical procedures for each case had to be as specified in the pathology report for each organ.   
FFPE tissue and stained with H&E using a documented, validated staining protocol. If applicable, slides of ancillary stains such as special histochemical and   
immunohistochemical (IHC) stains utilized for assessment of primary diagnosis had to be available and evaluable.   
When viewed by the Screening Pathologists, the slide(s) included had to match the signout diagnosis used as the study’s reference diagnosis.

# Exclusion Criteria:

Archived slides for the respective case were in poor condition. Indicators of poor condition   
included, but were not limited to, fading of the H&E stain, irremovable markings, air   
bubbles under the cover slip, cracks, and any issues that would affect the ability of the slide(s) to be scanned. The organ/procedure subtype counts exceed that allocated for the study.   
The H&E-stained slides that were used for the original sign-out diagnosis are not available at the site, and re-cuts were not available.   
If applicable, ancillary stain slides (IHC or special stain slides) that were used for the original artifacts. Control slides for the IHC or special stain are not available.   
The slides needed to support the original sign-out diagnosis require either a special light source (e.g., a mercury lamp for fluorescence microscopy) or special filters (e.g., for polarized light).   
Only frozen sections or gross specimens are available for the case. Note: Cases with frozen sections could be included if FFPE slides with non-frozen sections demonstrated one of the intended diagnoses; only the frozen section slides were excluded.   
Significant clinical and ancillary information that was used to establish the original diagnosis is missing.

● The signed-out date would have been less than 1 year prior to the study start date. More than 1 specimen per patient was selected.

After the reader pathologists at each site completed the review of the study cases and the primary diagnosis case report forms (CRF), three independent pathologist adjudicators reviewed the study reader’s diagnosis and compared it with the original “signed out” diagnosis (reference) to determine concordance, minor discordance, or major discordance between the study diagnosis (by WSI-DR and glass methods-MR) and original “signed out” diagnosis. A third pathologist adjudicator was used if disagreement occurred between the first two adjudicators on the classification of a “major” discordance. The original signed-out diagnosis is based on the original sign-out pathologic diagnosis rendered at the institutions using an optical (light) microscope. A major discordance was defined as a difference in diagnosis that would be associated with a clinically important difference in patient management. A minor discordance was defined as a difference in diagnosis that would not be associated with a clinically important difference in patient management. If there was a disagreement between the 2 adjudicators, a third adjudication pathologist reviewed the case to achieve majority consensus.

The study acceptance criteria were as follows: The upper bound of the two-sided $9 5 \%$ CI of the difference between the overall major discordance rates of WSI diagnoses and glass slide based diagnoses is $\leq 4 \%$ .

# Study Results:

A total of 7562 DR diagnoses paired with $7 5 6 2 \mathrm { M R }$ diagnoses adjudicated by the adjudication panel had consensus scores and were included in the statistical analyses. The observed overall agreement rate, i.e., over all sites, Reading Pathologists and organs was $9 2 . 0 0 \%$ for DR modality and $9 2 . 6 1 \%$ for MR modality. The DR-MR difference in agreement rate was $- 0 . 6 1 \%$ ( $9 5 \%$ CI: $- 1 . 2 0 \%$ , $0 . 0 0 \%$ ).

In addition to the observed analysis, a Generalized Linear Mixed Model (GLIMMIX) logistic regression was conducted on the study population to demonstrate the non-inferiority of the DR agreement rate as compared to the MR agreement rate. For each reading result and reading mode, the dependent variable was the agreement with sign-out diagnosis status. The model accounted for fixed study effects (i.e., reading modality and organ type) and random study effects (i.e., site and reader nested within site). The agreement rates as estimated by the GLIMMIX logistic model (“modeled”) resulted in similar proportions as the study point estimates, i.e., $9 1 . 5 4 \%$ for DR modality and $9 2 . 1 6 \%$ for MR modality. The DR-MR difference in agreement rate was $- 0 . 6 2 \%$ , with derived 2-sided $9 5 \%$ CI of $[ - 1 . 6 0 \%$ , $0 . 2 0 \% ]$ . These model results fail to show any statistically significant difference between the 2 reading modalities.

The lower limit of the $9 5 \%$ confidence interval of DR-MR was greater than the pre-specified non-inferiority margin of $- 4 \%$ , and therefore, the DR modality using Roche Digital Pathology Dx was demonstrated to be non-inferior to the MR modality using light microscopy. Thus, the study met the primary objective.

Table 6. Clinical Study Results Based on Major Discordance Rates   

<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=3>Whole Slide Imaging Review(DR)</td><td rowspan=1 colspan=3>Light Microscope Slide Review(MR)</td><td rowspan=1 colspan=2>Difference (DR - MR)</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>TotalReads</td><td rowspan=1 colspan=1>%Discordant</td><td rowspan=1 colspan=1>95% CI</td><td rowspan=1 colspan=1>TotalReads</td><td rowspan=1 colspan=1>%discordant</td><td rowspan=1 colspan=1>95% CI</td><td rowspan=1 colspan=1>%discordant</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Observed</td><td rowspan=1 colspan=1>7562</td><td rowspan=1 colspan=1>8.00</td><td rowspan=1 colspan=1>6.73, 9.27</td><td rowspan=1 colspan=1>7562</td><td rowspan=1 colspan=1>7.39</td><td rowspan=1 colspan=1>6.11, 8.78</td><td rowspan=1 colspan=1>0.61</td><td rowspan=1 colspan=1>-0.35, 1.59</td></tr><tr><td rowspan=1 colspan=1>Model</td><td rowspan=1 colspan=1>7725</td><td rowspan=1 colspan=1>8.46</td><td rowspan=1 colspan=1>7.35, 9.71</td><td rowspan=1 colspan=1>7744</td><td rowspan=1 colspan=1>7.84</td><td rowspan=1 colspan=1>6.80, 9.12</td><td rowspan=1 colspan=1>0.62</td><td rowspan=1 colspan=1>-0.26, 1.50</td></tr></table>

The differences in major discordance rates by organ types for the full cohort between WSIR and MSR are shown in the table below.

Table 7. Major Discordance Rates by Organ   

<table><tr><td colspan="1" rowspan="1">Organ Type</td><td colspan="1" rowspan="1">Digital Read(DR)</td><td colspan="1" rowspan="1">Manual Read(MR)</td><td colspan="1" rowspan="1">Difference inAgreement(DR-MR)</td></tr><tr><td colspan="1" rowspan="1">Anus/ Perianal</td><td colspan="1" rowspan="1">93.0%</td><td colspan="1" rowspan="1">95.7%</td><td colspan="1" rowspan="1">-2.7%</td></tr><tr><td colspan="1" rowspan="1">Appendix</td><td colspan="1" rowspan="1">98.4%</td><td colspan="1" rowspan="1">100.0%</td><td colspan="1" rowspan="1">-1.6%</td></tr><tr><td colspan="1" rowspan="1">Bladder</td><td colspan="1" rowspan="1">85.9%</td><td colspan="1" rowspan="1">87.8%</td><td colspan="1" rowspan="1">-1.8%</td></tr><tr><td colspan="1" rowspan="1">Brain/ Neurological</td><td colspan="1" rowspan="1">94.3%</td><td colspan="1" rowspan="1">92.4%</td><td colspan="1" rowspan="1">1.9%</td></tr><tr><td colspan="1" rowspan="1">Breast</td><td colspan="1" rowspan="1">91.0%</td><td colspan="1" rowspan="1">93.2%</td><td colspan="1" rowspan="1">-2.1%</td></tr><tr><td colspan="1" rowspan="1">Colorectal</td><td colspan="1" rowspan="1">93.2%</td><td colspan="1" rowspan="1">93.0%</td><td colspan="1" rowspan="1">0.2%</td></tr><tr><td colspan="1" rowspan="1">Endocrine</td><td colspan="1" rowspan="1">91.3%</td><td colspan="1" rowspan="1">92.1%</td><td colspan="1" rowspan="1">-0.8%</td></tr><tr><td colspan="1" rowspan="1">GE Junction</td><td colspan="1" rowspan="1">90.7%</td><td colspan="1" rowspan="1">91.5%</td><td colspan="1" rowspan="1">-0.9%</td></tr><tr><td colspan="1" rowspan="1">Gallbladder</td><td colspan="1" rowspan="1">100.0%</td><td colspan="1" rowspan="1">100.0%</td><td colspan="1" rowspan="1">0.0%</td></tr><tr><td colspan="1" rowspan="1">Gynecological</td><td colspan="1" rowspan="1">89.6%</td><td colspan="1" rowspan="1">89.6%</td><td colspan="1" rowspan="1">0.0%</td></tr><tr><td colspan="1" rowspan="1">Hernial/ Peritoneal</td><td colspan="1" rowspan="1">100.0%</td><td colspan="1" rowspan="1">100.0%</td><td colspan="1" rowspan="1">0.0%</td></tr><tr><td colspan="1" rowspan="1">Kidney, Neoplastic</td><td colspan="1" rowspan="1">96.2%</td><td colspan="1" rowspan="1">94.9%</td><td colspan="1" rowspan="1">1.3%</td></tr><tr><td colspan="1" rowspan="1">Liver/ Bile duct, Neoplastic</td><td colspan="1" rowspan="1">97.0%</td><td colspan="1" rowspan="1">98.5%</td><td colspan="1" rowspan="1">-1.5%</td></tr><tr><td colspan="1" rowspan="1">Lung/Bronchus/ Larynx /OralCavity/ Nasopharynx</td><td colspan="1" rowspan="1">89.4%</td><td colspan="1" rowspan="1">92.3%</td><td colspan="1" rowspan="1">-2.9%</td></tr><tr><td colspan="1" rowspan="1">Lymph Node</td><td colspan="1" rowspan="1">97.1%</td><td colspan="1" rowspan="1">97.8%</td><td colspan="1" rowspan="1">-0.7%</td></tr><tr><td colspan="1" rowspan="1">Prostate</td><td colspan="1" rowspan="1">93.4%</td><td colspan="1" rowspan="1">92.9%</td><td colspan="1" rowspan="1">0.5%</td></tr><tr><td colspan="1" rowspan="1">Salivary Gland</td><td colspan="1" rowspan="1">95.3%</td><td colspan="1" rowspan="1">94.8%</td><td colspan="1" rowspan="1">0.5%</td></tr><tr><td colspan="1" rowspan="1">Skin</td><td colspan="1" rowspan="1">89.6%</td><td colspan="1" rowspan="1">89.4%</td><td colspan="1" rowspan="1">0.2%</td></tr><tr><td colspan="1" rowspan="1">Soft TissueTumors</td><td colspan="1" rowspan="1">96.6%</td><td colspan="1" rowspan="1">93.1%</td><td colspan="1" rowspan="1">3.4%</td></tr><tr><td colspan="1" rowspan="1">Stomach</td><td colspan="1" rowspan="1">92.4%</td><td colspan="1" rowspan="1">93.6%</td><td colspan="1" rowspan="1">-1.2%</td></tr><tr><td colspan="1" rowspan="1">Overall</td><td colspan="1" rowspan="1">92.0%</td><td colspan="1" rowspan="1">92.6%</td><td colspan="1" rowspan="1">-0.6%</td></tr></table>

The clinical study was not powered to analyze the results by individual organ site or diagnosis. The difference in modality agreement, DR-MR, ranged from $- 2 . 9 \%$ for lung to $3 . 4 \%$ for soft tissue tumors. Three organ types, gallbladder, gynecological, and hernial/peritoneal had no differences (difference between reading modalities of $0 . 0 \%$ . For all organ types, the overall agreement rate was $9 2 . 0 \%$ for DR and $9 2 . 6 \%$ for MR, with a difference in agreement (DR-MR) of $- 0 . 6 \%$ . The lowest agreement in both modalities was observed with bladder cases, with an agreement rate of $8 5 . 9 \%$ for DR and $8 7 . 8 \%$ for MR. Subset of cases in the study were more difficult to adjudicate by both MR or DR reading modalities which may have contributed to the higher discordance rates.

When considering those cases where all four readers at the site provided successfully adjudicated diagnoses for both DR and MR, there were a total of 9552 reader pairs for agreement rate calculation. Overall, when considering all reader comparisons across all sites, the between-reader agreement rate was $9 1 . 4 \%$ ( $9 5 \%$ CI: 90.8, 91.9) for MR, and $9 0 . 6 \%$ ( $9 5 \%$ CI: 90.0, 91.1) for DR. The between-reader agreement rate ranged from $8 6 . 9 \%$ to $9 5 . 2 \%$ for MR, and $8 5 . 1 \%$ to $9 4 . 5 \%$ for DR.

# D. Human Factor Study:

Human factors studies designed to assess performance of critical user tasks and use scenarios by representative users, including anatomic pathology lab technicians and pathologists were conducted. Information provided included a list of all critical user tasks and a description of the process that was followed. A systematic evaluation of simulated use by representative participants (17 technicians and 18 pathologists) performing all tasks (including critical tasks) required for operation of the system, and subjective assessment of potential failure modes was provided. All participants were able to perform all tasks (including the critical tasks), and no critical task failures were observed. There were some occasional difficulties However, all user difficulties observed in the studies had minimal impact on the perception of the usability, and no difficulties or failures were observed performing tasks that could lead to permanent or serious patient harm. In all instances, both pathologists and histopathology technicians were able to identify cases and ensure that all information needed to perform primary diagnosis was available and accessible.

# E. Other Supportive Instrument Performance Characteristics Data: Not applicable

# VIII Proposed Labeling:

The labeling is sufficient, and it satisfies the requirements of 21 CFR Parts 801 and 809, as applicable, and the special controls for this device type under 21 CFR 864.3700.

# IX Conclusion:

The submitted information in this premarket notification is complete and supports a substantial equivalence decision.