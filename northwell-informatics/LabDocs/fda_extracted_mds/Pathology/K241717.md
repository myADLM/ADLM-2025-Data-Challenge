Shandon Diagnostics Limited   
Naveen Kaki   
Regulatory Affairs Specialist   
Tudor Road, Manor Park, Cheshire   
Runcorn, WA7 1TA   
United Kingdom

Re: K241717 Trade/Device Name: Epredia E1000 Dx Digital Pathology Solution Regulation Number: 21 CFR 864.3700 Regulation Name: Whole slide imaging system Regulatory Class: Class II Product Code: PSY Dated: June 13, 2024 Received: June 14, 2024

Dear Naveen Kaki:

We have reviewed your section 510(k) premarket notification of intent to market the device referenced above and have determined the device is substantially equivalent (for the indications for use stated in the enclosure) to legally marketed predicate devices marketed in interstate commerce prior to May 28, 1976, the enactment date of the Medical Device Amendments, or to devices that have been reclassified in accordance with the provisions of the Federal Food, Drug, and Cosmetic Act (the Act) that do not require approval of a premarket approval application (PMA). You may, therefore, market the device, subject to the general controls provisions of the Act. Although this letter refers to your product as a device, please be aware that some cleared products may instead be combination products. The 510(k) Premarket Notification Database available at https://www.accessdata.fda.gov/scripts/cdrh/cfdocs/cfpmn/pmn.cfm identifies combination product submissions. The general controls provisions of the Act include requirements for annual registration, listing of devices, good manufacturing practice, labeling, and prohibitions against misbranding and adulteration. Please note: CDRH does not evaluate information related to contract liability warranties. We remind you, however, that device labeling must be truthful and not misleading.

If your device is classified (see above) into either class II (Special Controls) or class III (PMA), it may be subject to additional controls. Existing major regulations affecting your device can be found in the Code of Federal Regulations, Title 21, Parts 800 to 898. In addition, FDA may publish further announcements concerning your device in the Federal Register.

Your device is also subject to, among other requirements, the Quality System (QS) regulation (21 CFR Part 820), which includes, but is not limited to, 21 CFR 820.30, Design controls; 21 CFR 820.90, Nonconforming product; and 21 CFR 820.100, Corrective and preventive action. Please note that regardless of whether a change requires premarket review, the QS regulation requires device manufacturers to review and approve changes to device design and production (21 CFR 820.30 and 21 CFR 820.70) and document changes and approvals in the device master record (21 CFR 820.181).

Please be advised that FDA's issuance of a substantial equivalence determination does not mean that FDA has made a determination that your device complies with other requirements of the Act or any Federal statutes and regulations administered by other Federal agencies. You must comply with all the Act's requirements, including, but not limited to: registration and listing (21 CFR Part 807); labeling (21 CFR Part 801 and Part 809); medical device reporting (reporting of medical device-related adverse events) (21 CFR Part 803) for devices or postmarketing safety reporting (21 CFR Part 4, Subpart B) for combination products (see https://www.fda.gov/combination-products/guidance-regulatory-information/postmarketing-safetyreporting-combination-products); good manufacturing practice requirements as set forth in the quality systems (QS) regulation (21 CFR Part 820) for devices or current good manufacturing practices (21 CFR Part 4, Subpart A) for combination products; and, if applicable, the electronic product radiation control provisions (Sections 531-542 of the Act); 21 CFR Parts 1000-1050.

All medical devices, including Class I and unclassified devices and combination product device constituent parts are required to be in compliance with the final Unique Device Identification System rule ("UDI Rule"). The UDI Rule requires, among other things, that a device bear a unique device identifier (UDI) on its label and package (21 CFR 801.20(a)) unless an exception or alternative applies (21 CFR 801.20(b)) and that the dates on the device label be formatted in accordance with 21 CFR 801.18. The UDI Rule (21 CFR 830.300(a) and 830.320(b)) also requires that certain information be submitted to the Global Unique Device Identification Database (GUDID) (21 CFR Part 830 Subpart E). For additional information on these requirements, please see the UDI System webpage at https://www.fda.gov/medical-devices/device-advicecomprehensive-regulatory-assistance/unique-device-identification-system-udi-system.

Also, please note the regulation entitled, "Misbranding by reference to premarket notification" (21 CFR 807.97). For questions regarding the reporting of adverse events under the MDR regulation (21 CFR Part 803), please go to https://www.fda.gov/medical-devices/medical-device-safety/medical-device-reportingmdr-how-report-medical-device-problems.

For comprehensive regulatory information about medical devices and radiation-emitting products, including information about labeling regulations, please see Device Advice (https://www.fda.gov/medical  
devices/device-advice-comprehensive-regulatory-assistance) and CDRH Learn   
(https://www.fda.gov/training-and-continuing-education/cdrh-learn). Additionally, you may contact the Division of Industry and Consumer Education (DICE) to ask a question about a specific regulatory topic. See the DICE website (https://www.fda.gov/medical-devices/device-advice-comprehensive-regulatoryassistance/contact-us-division-industry-and-consumer-education-dice) for more information or contact DICE by email (DICE@fda.hhs.gov) or phone (1-800-638-2041 or 301-796-7100).

Sincerely,

# Shyam Kalavar -S

Shyam Kalavar   
Deputy Branch Chief   
Division of Molecular Genetics and Pathology   
OHT7: Office of In Vitro Diagnostics   
Office of Product Evaluation and Quality   
Center for Devices and Radiological Health

Enclosure

Device Name Epredia E1000 Dx Digital Pathology Solution

Indications for Use (Describe)

The Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is an automated digital slide creation, viewing, and management system. The Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of surgical pathology slides prepared from formalin-fixed paraffin embedded (FFPE) tissue. The Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is not intended for use with frozen section, cytology, or non-FFPE hematopathology specimens.

The Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution consists of a Scanner $\mathrm { E 1 0 0 0 D x }$ Digital Pathology Scanner), which generates images in MRXS image file format, $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Scanner Software, Image Management System (E1000 Dx IMS), $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Viewer Software, and Display (Barco MDPC-8127). The Epredia E1000 Dx Digital Pathology Solution is for creation and viewing of digital images of scanned glass slides that would otherwise be appropriate for manual visualization by conventional light microscopy. It is the responsibility of a qualified pathologist to employ appropriate procedures and safeguards to assure the validity of the interpretation of images obtained using Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution.

This section applies only to requirements of the Paperwork Reduction Act of 1995.

# \*DO NOT SEND YOUR COMPLETED FORM TO THE PRA STAFF EMAIL ADDRESS BELOW.\*

The burden time for this collection of information is estimated to average 79 hours per response, including the time to review instructions, search existing data sources, gather and maintain the data needed and complete and review the collection of information. Send comments regarding this burden estimate or any other aspect of this information collection, including suggestions for reducing this burden, to:

Department of Health and Human Services Food and Drug Administration Office of Chief Information Officer Paperwork Reduction Act (PRA) Staff PRAStaff@fda.hhs.gov

“An agency may not conduct or sponsor, and a person is not required to respond to, a collection of information unless it displays a currently valid OMB number.”

# 510(k) Summary

# Epredia E1000 Dx Digital Pathology Solution

Date prepared: February 26, 2025

# Submitter

Shandon Diagnostics, Ltd..   
Tudor Road, Manor Park,   
Runcorn, Cheshire, WA7 1TA, United Kingdom.

# Contact Person

Naveen Kaki, M.Sc. Telephone: (857) 263-1783. Email: Naveen.kaki@epredia.com

# Device

Proprietary Name:   
Classification Name:   
Regulation Number:   
Regulatory Classification:   
Product Code:   
Review Panel:   
510(k) Number:   
Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution   
Whole Slide Imaging System   
21 CFR 864.3700   
Class II   
PSY   
88 – Pathology   
K241717

# Predicate Device

Proprietary Name: Submission Number:

Philips IntelliSite Pathology Solution (PIPS) DEN160056

# I. Intended Use

The Epredia $\operatorname { E } 1 0 0 0 \ \operatorname { D } \mathbf { x }$ Digital Pathology Solution is an automated digital slide creation, viewing, and management system. The Epredia E1000 Dx Digital Pathology Solution is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of surgical pathology slides prepared from formalin-fixed paraffin embedded (FFPE) tissue. The Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is not intended for use with frozen section, cytology, or non-FFPE hematopathology specimens.

The Epredia $\operatorname { E } 1 0 0 0 \ \operatorname { D } \mathbf { x }$ Digital Pathology Solution consists of a scanner $\mathrm { E 1 0 0 0 ~ D x }$ Digital Pathology Scanner), which generates images in the MRXS image file format, $\operatorname { E } 1 0 0 0 \ \operatorname { D } \mathbf { x }$ Scanner Software, Image Management System (E1000 Dx IMS), $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Viewer Software, and Display (Barco MDPC-8127). The Epredia $\operatorname { E } 1 0 0 0 \ \operatorname { D } \mathbf { x }$ Digital Pathology Solution is for creation and viewing of digital images of scanned glass slides that would otherwise be appropriate for manual visualization by conventional light microscopy. It is the responsibility of a qualified pathologist to employ appropriate procedures and safeguards to assure the validity of the interpretation of images obtained using Epredia E1000 Dx Digital Pathology Solution.

# II. Device Description

The $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is a high-capacity, automated whole slide imaging system for the creation, viewing, and management of digital images of surgical pathology slides. It allows whole slide digital images to be viewed on a display monitor that would otherwise be appropriate for manual visualization by conventional brightfield microscopy.

The $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution consists of the following three components: Scanner component:

E1000 Dx Digital Pathology Scanner with E1000 firmware version 2.0.3 E1000 Dx Scanner Software version 2.0.3

Viewer component:

E1000 Dx Image Management System (IMS) Server version 2.3.2   
E1000 Dx Viewer Software version 2.7.2

Display component:

Barco MDPC-8127

The $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution automatically creates digital whole slide images by scanning formalin-fixed, paraffin-embedded (FFPE) tissue slides, with a capacity to process up to 1,000 slides. The E1000 Dx Scanner Software (EDSS), which runs on the scanner workstation, controls the operation of the E1000 Dx Digital Pathology Scanner. The scanner workstation, provided with the $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution, includes a PC, monitor, keyboard, and mouse. The solution uses a proprietary MRXS format to store and transmit images between the E1000 Dx Digital Pathology Scanner and the $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Image Management System (IMS).

The E1000 Dx IMS is a software component intended for use with the Barco MDPC-8127 display monitor and runs on a separate, customer-provided pathologist viewing workstation PC. The $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Viewer, an application managed through the E1000 Dx IMS, allows the obtained digital whole slide images to be annotated, stored, accessed, and examined on Barco MDPC-8127 video display monitor. This functionality aids pathologists in interpreting digital images as an alternative to conventional brightfield microscopy.

III. Comparison of technological characteristics with the predicate device   

<table><tr><td>Items</td><td>K241717 Epredia E1000 Dx Digital Pathology</td><td>DEN160056 Philips IntelliSite Pathology Solution (PIPS)</td></tr><tr><td colspan="3">Solution Similarities</td></tr><tr><td>Indications For Use</td><td>The Epredia E1000 Dx Digital Pathology Solution is an automated digital slide creation, viewing, and management system. The Epredia E1000 Dx Digital Pathology Solution is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of surgical pathology slides prepared from formalin-fixed paraffin embedded (FFPE) tissue. The Epredia E1000 Dx Digital Pathology Solution is not intended for use with frozen section, cytology, or non- FFPE hematopathology specimens.</td><td>The Philips IntelliSite Pathology Solution (PIPS) is an automated digital slide creation, viewing, and management system. The PIPS is intended for in vitro diagnostic use as an aid to the pathologist to review and interpret digital images of surgical pathology slides prepared from formalin-fixed paraffin embedded (FFPE) tissue. The PIPS is not intended for use with frozen section, cytology, or non-FFPE hematopathology specimens.</td></tr><tr><td colspan="1" rowspan="1"></td><td colspan="1" rowspan="1">The Epredia E1000 Dx Digital PathologySolution consists of a scanner (E1000 DxDigital Pathology Scanner), which generatesimages in the MRXS image file format,E1000 Dx Scanner Software, ImageManagement System (E1000 Dx IMS),E1000 Dx Viewer Software, and Display(Barco MDPC-8127). The Epredia E1000 DxDigital Pathology Solution is for creation andviewing of digital images of scanned glassslides that would otherwise be appropriate formanual visualization by conventional lightmicroscopy. It is the responsibility of aqualified pathologist to employ appropriateprocedures and safeguards to assure thevalidity of the interpretation of imagesobtained using Epredia E1000 Dx DigitalPathology Solution.</td><td colspan="1" rowspan="1">The PIPS comprises the Image ManagementSystem (IMS), the Ultra Fast Scanner (UFS)and Display. The PIPS is for creation andviewing of digital images of scanned glassslides that would otherwise be appropriate formanual visualization by conventional lightmicroscopy. It is the responsibility of aqualified pathologist to employ appropriateprocedures and safeguards to assure thevalidity of the interpretation of imagesobtained using PIPS.</td></tr><tr><td colspan="1" rowspan="1">Specimentype</td><td colspan="1" rowspan="1">Surgical pathology slides prepared fromformalin-fixed, paraffin-embedded tissue.</td><td colspan="1" rowspan="1">Same</td></tr><tr><td colspan="1" rowspan="1">Devicecomponents</td><td colspan="1" rowspan="1">E1000 Dx Digital Pathology Scanner, E1000Dx IMS and a display (K203364)</td><td colspan="1" rowspan="1">Similar - PIPS Ultra Fast Scanner, ImageManagement System and a display.</td></tr><tr><td colspan="3" rowspan="1">Differences</td></tr><tr><td colspan="1" rowspan="1">Slide Feedercapacity</td><td colspan="1" rowspan="1">1000 Slides</td><td colspan="1" rowspan="1">300 Slides</td></tr><tr><td colspan="1" rowspan="1">Image FileFormats</td><td colspan="1" rowspan="1">MRXS</td><td colspan="1" rowspan="1">iSyntax</td></tr><tr><td colspan="1" rowspan="1">MonitorDisplay</td><td colspan="1" rowspan="1">Barco MDPC-8127</td><td colspan="1" rowspan="1">PS27QHDCR</td></tr></table>

Despite these technological differences, the Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution raised no new safety or efficacy concerns. This conclusion is supported by performance studies, verification, and validation activities conducted during the controlled hardware and software development processes.

# IV. PERFORMANCE DATA

# 1. Technical Studies

Studies were conducted to evaluate the performance of the $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution in accordance with the special controls listed in 21 CFR 864.3700 Whole Slide Imaging System and the FDA's guidance document titled "Technical Performance Assessment of Digital Pathology Whole Slide Imaging Devices." A detailed description of the device, along with the results of passed bench testing at the component level, including the following, were submitted as appropriate:

a) Slide Feeder   
b) Light Source   
c) Imaging Optics   
d) Mechanical Scanner Movement   
e) Digital Imaging Sensor   
f) Image Processing Software   
g) Image Composition   
h) Image Files Format   
i) Image Review Manipulation Software   
j) Computer Environment   
k) Display   
l) Color Reproducibility   
m) Spatial Resolution   
n) Focusing Test   
o) Whole Slide Tissue Coverage   
p) Stitching Error   
q) Turnaround Time

# 2. User Interface/Human Factors Validation

Critical tasks were identified internally by conducting a detailed uFMEA (user Failure Modes and Effects Analysis). The safety and efficacy of risk mitigation processes were validated externally in a study involving two distinct user groups: laboratory technicians and pathologists to assess software interface, hardware interface, and product labelling. Both user groups perceived that the risk mitigation steps for critical tasks were successfully implemented and that the $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution can be used safely and effectively by its intended users, for its intended purpose, and in its intended use environment.

# 3. Electromagnetic Compatibility (EMC) Testing

Electrical safety testing and electromagnetic compatibility testing, conducted in accordance with the standards outlined in IEC 61010-1, IEC 61010-2-101, and IEC 61326-2-6, respectively, yielded passing results.

# 4. Clinical Testing

# a) Clinical Accuracy Study

A multi-centered, blinded, and randomized study was conducted to demonstrate that viewing, reviewing, and diagnosing digital images of surgical pathology slides prepared from tissue slides using the $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is non-inferior to an optical microscope by determining the difference in major discordance rate between manual digital (MD) and manual optical (MO) modalities when compared to the main sign-out diagnosis (SD). The observed major discordance rates were calculated using a Generalized Linear Mixed Model (GLIMMIX) logistic regression.

The major discordance rate between MD and SD was observed to be $2 . 5 4 \%$ , and the major discordance rate between MO and SD was observed to be $2 . 6 5 \%$ . The overall major discordance rates estimated by the generalized linear model were $2 . 5 1 \%$ $9 5 \%$ CI: $2 . 2 6 \%$ ; $2 . 7 9 \% )$ for MD and $2 . 5 9 \%$ $9 5 \%$ CI: $2 . 2 9 \%$ ; $2 . 8 2 \%$ ) for MO. The estimated difference in major discordance between the MD and MO rates was calculated to be $- 0 . 1 5 \%$ ( $9 5 \%$ CI: - $0 . 4 0 \%$ , $0 . 4 1 \%$ ). The study met its acceptance criteria, as defined in the protocol.

Table 1: Overall Major Discordance Rate for MD and MO   

<table><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=3>MD: Major Discordance Rate</td><td rowspan=1 colspan=3>MO: Major Discordance Rate</td><td rowspan=1 colspan=2>DifferenceMD - MO</td></tr><tr><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>N</td><td rowspan=1 colspan=1>%</td><td rowspan=1 colspan=1>95% CI</td><td rowspan=1 colspan=1>N</td><td rowspan=1 colspan=1>%</td><td rowspan=1 colspan=1>95% CI</td><td rowspan=1 colspan=1>%</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Observed</td><td rowspan=2 colspan=1>3897</td><td rowspan=1 colspan=1>2.54%</td><td rowspan=1 colspan=1></td><td rowspan=2 colspan=1>3881</td><td rowspan=1 colspan=1>2.65%</td><td rowspan=1 colspan=1></td><td rowspan=1 colspan=1>-0.11%</td><td rowspan=1 colspan=1></td></tr><tr><td rowspan=1 colspan=1>Modeled</td><td rowspan=1 colspan=1>2.51%</td><td rowspan=1 colspan=1>(2.26%; 2.79%)</td><td rowspan=1 colspan=1>2.59%</td><td rowspan=1 colspan=1>(2.29%, 2.82%)</td><td rowspan=1 colspan=1>-0.15%</td><td rowspan=1 colspan=1>(-0.40%, 0.41%)</td></tr></table>

The observed difference in major discordance between MD-MO for the Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution is $- 0 . 1 1 \%$ . The data obtained from the study demonstrate that the $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution performs substantially equivalent to its predicate device.

# b) Precision Study

A study was conducted to evaluate the precision of the Epredia $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution. The study included intra-system, inter-system repeatability and inter-site reproducibility using a comprehensive set of clinical specimens with defined, clinically relevant histologic features from various organ systems.

# 1. Intra-System Repeatability Study

The intra-system repeatability study included scanned WSIs of glass slides which were selected and enrolled according to the specified procedure. From this set, fields of view (FOVs) with one selected feature each were extracted. Additionally, “wildcard” FOVs were selected from other slides following the same procedure to minimize or avoid bias by the reading pathologist, though these wildcard FOVs were not included in the primary analysis. The study slides were divided equally and randomized across three systems at one site. Each slide set was scanned three times, with a minimum of six hours between each scan on each system. Randomly selected FOVs from the three different systems and three different iterations were read by three different reading pathologists (RPs). The pathologists recorded the presence of each observed feature on a checklist for each predetermined magnification level.

The data obtained from this evaluation for $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution met the acceptance criteria of a lower limit of the $9 5 \%$ Confidence interval (CI) greater than $8 5 \%$ , with an Average Positive Agreement of $9 6 . 9 \%$ (lower limit of $9 6 . 1 \%$ ).

Table 2: Intra-system Precision Agreement Rates   

<table><tr><td rowspan=2 colspan=1>System</td><td rowspan=2 colspan=1>Number ofPairwiseAgreements*</td><td rowspan=2 colspan=1>Number ofComparisonPairs</td><td rowspan=1 colspan=2>Agreement Rate</td></tr><tr><td rowspan=1 colspan=1>%</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>System 1</td><td rowspan=1 colspan=1>820</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>98.0</td><td rowspan=1 colspan=1>(97.3, 98.8)</td></tr><tr><td rowspan=1 colspan=1>System 2</td><td rowspan=1 colspan=1>803</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>95.9</td><td rowspan=1 colspan=1>(94.4, 97.1)</td></tr><tr><td rowspan=1 colspan=1>System 3</td><td rowspan=1 colspan=1>810</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>96.8</td><td rowspan=1 colspan=1>(95.7, 97.8)</td></tr><tr><td rowspan=1 colspan=1>Total</td><td rowspan=1 colspan=1>2,433</td><td rowspan=1 colspan=1>2,511</td><td rowspan=1 colspan=1>96.9</td><td rowspan=1 colspan=1>(96.1, 97.4)</td></tr></table>

\*Number of agreements represents the number of a positive agreements with the original assessment

The inter-system repeatability study utilized the full set of scanned WSIs of glass slides from the intra-system study, including the same extracted FOVs, features, and wildcards. Each slide was scanned once on each system. Three reading pathologists then evaluated each enrolled FOV once on each system. The pathologists recorded the presence of each observed feature on a checklist for each magnification level.

The data obtained from this study met the acceptance criteria of a lower limit of $9 5 \%$ Confidence interval (CI) greater than $8 5 \%$ , with an Average Positive Agreement of $9 5 . 1 \%$ (lower limit of $9 4 . 1 \%$ ).

Table 3: Inter-system Precision Agreement Rates   

<table><tr><td rowspan=2 colspan=1>System</td><td rowspan=2 colspan=1>Number ofPairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparison Pairs</td><td rowspan=1 colspan=2>Agreement Rate</td></tr><tr><td rowspan=1 colspan=1>%</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>System 1 vs 2</td><td rowspan=1 colspan=1>788</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>94.1</td><td rowspan=1 colspan=1>(91.2, 95.9)</td></tr><tr><td rowspan=1 colspan=1>System 1 vs 3</td><td rowspan=1 colspan=1>793</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>94.7</td><td rowspan=1 colspan=1>(92.6, 96.4)</td></tr><tr><td rowspan=1 colspan=1>System 2 vs 3</td><td rowspan=1 colspan=1>808</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>96.5</td><td rowspan=1 colspan=1>(94.7, 97.8)</td></tr><tr><td rowspan=1 colspan=1>Total</td><td rowspan=1 colspan=1>2,389</td><td rowspan=1 colspan=1>2,511</td><td rowspan=1 colspan=1>95.1</td><td rowspan=1 colspan=1>(94.0, 96.1)</td></tr></table>

# 3. Inter-Site Reproducibility:

For the inter-site study, the wildcards and FOVs from the intra-system and inter-system repeatability studies were used as the study FOVs. The study involved three different reading pathologists, each located at one of three different sites, each equipped with its own $\operatorname { E } 1 0 0 0 \operatorname { D } \mathbf { x }$ Digital Pathology Solution. The order of FOV evaluation at each site was randomly determined. Each pathologist evaluated each FOV once and recorded the presence of each observed feature on a checklist for each magnification level.

The data obtained from this study met the acceptance criteria of a lower limit of $9 5 \%$ Confidence interval (CI) greater than $8 5 \%$ , with an Average Positive Agreement of $9 5 . 4 \%$ (lower limit of $9 3 . 6 \%$ ).

Table 4: Inter-site Reproducibility Agreement Rates   

<table><tr><td rowspan=2 colspan=1>System</td><td rowspan=2 colspan=1>Number ofPairwiseAgreements</td><td rowspan=2 colspan=1>Number ofComparison Pairs</td><td rowspan=1 colspan=2>Agreement Rate</td></tr><tr><td rowspan=1 colspan=1>%</td><td rowspan=1 colspan=1>95% CI</td></tr><tr><td rowspan=1 colspan=1>Site 1 vs 2</td><td rowspan=1 colspan=1>261</td><td rowspan=1 colspan=1>279</td><td rowspan=1 colspan=1>93.5</td><td rowspan=1 colspan=1>(89.2, 96.6)</td></tr><tr><td rowspan=1 colspan=1>Site 1 vs 3</td><td rowspan=1 colspan=1>268</td><td rowspan=1 colspan=1>279</td><td rowspan=1 colspan=1>96.1</td><td rowspan=1 colspan=1>(92.4, 98.3)</td></tr><tr><td rowspan=1 colspan=1>Site 2 vs 3</td><td rowspan=1 colspan=1>270</td><td rowspan=1 colspan=1>279</td><td rowspan=1 colspan=1>96.8</td><td rowspan=1 colspan=1>(93.3, 98.7)</td></tr><tr><td rowspan=1 colspan=1>Total</td><td rowspan=1 colspan=1>799</td><td rowspan=1 colspan=1>837</td><td rowspan=1 colspan=1>95.4</td><td rowspan=1 colspan=1>(93.5, 97.0)</td></tr></table>

# V. CONCLUSIONS

The study results demonstrate that E1000 Dx Digital Pathology Solution is substantially equivalent to the predicate device.